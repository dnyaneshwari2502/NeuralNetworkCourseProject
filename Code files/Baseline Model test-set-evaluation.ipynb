{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10985935,"sourceType":"datasetVersion","datasetId":6837553},{"sourceId":11234864,"sourceType":"datasetVersion","datasetId":7018433},{"sourceId":11234998,"sourceType":"datasetVersion","datasetId":7018522},{"sourceId":11235019,"sourceType":"datasetVersion","datasetId":7018535}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip3 install Levenshtein","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T14:48:07.774317Z","iopub.execute_input":"2025-04-08T14:48:07.774706Z","iopub.status.idle":"2025-04-08T14:48:14.042618Z","shell.execute_reply.started":"2025-04-08T14:48:07.774675Z","shell.execute_reply":"2025-04-08T14:48:14.041554Z"}},"outputs":[{"name":"stdout","text":"Collecting Levenshtein\n  Downloading levenshtein-0.27.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\nCollecting rapidfuzz<4.0.0,>=3.9.0 (from Levenshtein)\n  Downloading rapidfuzz-3.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\nDownloading levenshtein-0.27.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (161 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.5/161.5 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading rapidfuzz-3.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m74.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: rapidfuzz, Levenshtein\nSuccessfully installed Levenshtein-0.27.1 rapidfuzz-3.13.0\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader\nimport torch\nimport torch.nn as nn\nimport torchaudio\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport numpy as np\nimport Levenshtein\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-08T14:48:14.043915Z","iopub.execute_input":"2025-04-08T14:48:14.044175Z","iopub.status.idle":"2025-04-08T14:48:18.270417Z","shell.execute_reply.started":"2025-04-08T14:48:14.044142Z","shell.execute_reply":"2025-04-08T14:48:18.269795Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"!ls /kaggle/input/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T14:48:18.271597Z","iopub.execute_input":"2025-04-08T14:48:18.271985Z","iopub.status.idle":"2025-04-08T14:48:18.399564Z","shell.execute_reply.started":"2025-04-08T14:48:18.271956Z","shell.execute_reply":"2025-04-08T14:48:18.398793Z"}},"outputs":[{"name":"stdout","text":"librispeech-datasets\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T14:48:18.401128Z","iopub.execute_input":"2025-04-08T14:48:18.401373Z","iopub.status.idle":"2025-04-08T14:48:18.457214Z","shell.execute_reply.started":"2025-04-08T14:48:18.401350Z","shell.execute_reply":"2025-04-08T14:48:18.456301Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}],"execution_count":5},{"cell_type":"markdown","source":"### Preprocessing Data","metadata":{}},{"cell_type":"code","source":"\ndataset_path = \"/kaggle/input/librispeech-datasets/\"\ndef download(dataset):\n    audioset = torchaudio.datasets.LIBRISPEECH(dataset_path+'/'+dataset,url=dataset,download=False)\n    return audioset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T14:48:18.458199Z","iopub.execute_input":"2025-04-08T14:48:18.458538Z","iopub.status.idle":"2025-04-08T14:48:18.471493Z","shell.execute_reply.started":"2025-04-08T14:48:18.458483Z","shell.execute_reply":"2025-04-08T14:48:18.470827Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"train_clean = download('train-clean-100')\ndev_clean = download('dev-clean')\ntest_clean = download('test-clean')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T14:48:18.472336Z","iopub.execute_input":"2025-04-08T14:48:18.472640Z","iopub.status.idle":"2025-04-08T14:48:35.554520Z","shell.execute_reply.started":"2025-04-08T14:48:18.472612Z","shell.execute_reply":"2025-04-08T14:48:35.553855Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"class Unigram():\n    def __init__(self,word_model_type):\n        self.word_model_type = 'unigram'\n        self.blank_id = 28\n        self.n_class = 29\n\n        self.SPACE = \"[space]\"\n        self.characters = \"' \" + self.SPACE + \" \" +\" \".join(\"abcdefghijklmnopqrstuvwxyz\")\n        self.tokens = self.characters.split(' ')\n\n        self.char_to_id = {char: idx for idx, char in enumerate(self.tokens)}\n        self.id_to_char = {idx: char for idx, char in enumerate(self.tokens)}\n\n    def text_to_int(self, sentence: str):\n        idx_sequence = []\n        for ch in sentence:\n            idx = self.char_to_id[self.SPACE] if ch == \" \" else self.char_to_id[ch]\n            idx_sequence.append(idx)\n        return idx_sequence\n\n    def int_to_text(self, indices):\n        sentence = []\n        for i in indices:\n            ch = self.id_to_char[i]\n            sentence.append(ch)\n        return \"\".join(sentence).replace(self.SPACE, \" \")\n\n\nword_encoding_model = Unigram('unigram')\noriginal = \"my name is olan\"\nencoded = word_encoding_model.text_to_int(original)\nreconstructed = word_encoding_model.int_to_text(encoded)\nprint(original)\nprint(encoded)\nprint(reconstructed)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T14:48:35.555305Z","iopub.execute_input":"2025-04-08T14:48:35.555551Z","iopub.status.idle":"2025-04-08T14:48:35.564199Z","shell.execute_reply.started":"2025-04-08T14:48:35.555519Z","shell.execute_reply":"2025-04-08T14:48:35.563259Z"}},"outputs":[{"name":"stdout","text":"my name is olan\n[14, 26, 1, 15, 2, 14, 6, 1, 10, 20, 1, 16, 13, 2, 15]\nmy name is olan\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"def preprocess(audioset,split,stride,word_model):\n\n        if split[:5] == \"train\":\n            train_pipe = nn.Sequential(\n                torchaudio.transforms.MelSpectrogram(sample_rate=16000, n_mels=128),\n                torchaudio.transforms.FrequencyMasking(freq_mask_param=15),\n                torchaudio.transforms.TimeMasking(time_mask_param=35))\n            augment_fn = train_pipe\n        else:\n            test_pipe = torchaudio.transforms.MelSpectrogram()\n            augment_fn = test_pipe\n      \n        spectrograms = []\n        indices = []\n        len_spectrograms = []\n        len_indices = []\n        \n        for waveform, _, transcript, _, _, _ in audioset:\n            # Augment audio data\n            spec = augment_fn(waveform).squeeze(0).transpose(0,1)\n            spectrograms.append(spec)\n\n            # Convert text transcript to sequence of ids\n            ids = torch.Tensor(word_model.text_to_int(transcript.lower()))\n            indices.append(ids)\n\n            # Append audio and text length\n            if stride == 2:\n                len_spec = spec.shape[0]//stride\n            else:\n                len_spec = spec.shape[0]//stride - 2\n            \n            len_spectrograms.append(len_spec)\n            len_indices.append(len(ids))\n        \n        # Zero pad\n        spectrograms = nn.utils.rnn.pad_sequence(spectrograms, batch_first=True).unsqueeze(1).transpose(2, 3)\n        indices = nn.utils.rnn.pad_sequence(indices, batch_first=True)\n\n        return spectrograms, indices, len_spectrograms, len_indices","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T14:48:35.566649Z","iopub.execute_input":"2025-04-08T14:48:35.566840Z","iopub.status.idle":"2025-04-08T14:48:35.583135Z","shell.execute_reply.started":"2025-04-08T14:48:35.566823Z","shell.execute_reply":"2025-04-08T14:48:35.582288Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def reading_data_sample(loader):\n    print(\"Data length : \",len(loader.dataset))\n    for batch_sample in loader:\n        print(\"Spectrogram shape:\", list(batch_sample[0].shape))\n        print(\"Label shape:\", list(batch_sample[1].shape))\n        print(\"Mel length (length of each spectrogram):\", batch_sample[2][:6], \"...\")\n        print(\"Idx length (length of each label):\", batch_sample[3][:6], \"...\")\n        break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T14:48:35.584440Z","iopub.execute_input":"2025-04-08T14:48:35.584763Z","iopub.status.idle":"2025-04-08T14:48:35.598534Z","shell.execute_reply.started":"2025-04-08T14:48:35.584730Z","shell.execute_reply":"2025-04-08T14:48:35.597806Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"#Best HP combination\nbatch_size = 16\nepochs = 10\nn_features = 128 \nstride = 2      \nlr = 0.0005\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T14:48:35.599295Z","iopub.execute_input":"2025-04-08T14:48:35.599540Z","iopub.status.idle":"2025-04-08T14:48:35.612639Z","shell.execute_reply.started":"2025-04-08T14:48:35.599494Z","shell.execute_reply":"2025-04-08T14:48:35.611976Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"train_loader  = DataLoader(dataset=train_clean,\n                               batch_size=batch_size,\n                               shuffle=False,\n                               collate_fn=lambda x: preprocess(x, \"train-clean-100\", stride, word_encoding_model))\n\n\ndev_clean_loader = DataLoader(dataset=dev_clean,\n                               batch_size=batch_size,\n                               shuffle=False,\n                               collate_fn=lambda x: preprocess(x, \"dev-clean\", stride, word_encoding_model))\n\n\ntest_clean_loader = DataLoader(dataset=test_clean,\n                               batch_size=batch_size,\n                               shuffle=False,\n                               collate_fn=lambda x: preprocess(x, \"test-clean\", stride, word_encoding_model))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T14:48:35.613557Z","iopub.execute_input":"2025-04-08T14:48:35.613850Z","iopub.status.idle":"2025-04-08T14:48:35.630966Z","shell.execute_reply.started":"2025-04-08T14:48:35.613821Z","shell.execute_reply":"2025-04-08T14:48:35.630051Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"print(f\"Train : {len(train_loader.dataset)} samples \")\nprint(f\"Dev Clean : {len(dev_clean_loader.dataset)} samples \")\nprint(f\"Test Clean : {len(test_clean_loader.dataset)} samples \")\nprint()\n\nreading_data_sample(train_loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T14:48:35.631801Z","iopub.execute_input":"2025-04-08T14:48:35.632072Z","iopub.status.idle":"2025-04-08T14:48:36.275275Z","shell.execute_reply.started":"2025-04-08T14:48:35.632041Z","shell.execute_reply":"2025-04-08T14:48:36.274362Z"}},"outputs":[{"name":"stdout","text":"Train : 28539 samples \nDev Clean : 2703 samples \nTest Clean : 2620 samples \n\nData length :  28539\nSpectrogram shape: [16, 1, 128, 1276]\nLabel shape: [16, 283]\nMel length (length of each spectrogram): [563, 638, 558, 588, 501, 607] ...\nIdx length (length of each label): [201, 283, 250, 268, 227, 263] ...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# The time dimension keeps varying so i am normalising on the fixed feature dimension\nclass LayerNorm(nn.Module):\n    def __init__(self, n_features):\n        super(LayerNorm, self).__init__()\n        self.layer_norm = nn.LayerNorm(n_features)\n    \n    def forward(self, x):\n        # x is of the form [batch,channels,n_features,time]\n        x = x.transpose(2, 3).contiguous()\n        x = self.layer_norm(x)\n        return x.transpose(2, 3).contiguous()\n\n\n\nclass ResNetInv(nn.Module):\n    def __init__(self, in_channels, out_channels, n_features, kernel, stride, drop_rate):\n        super(ResNetInv, self).__init__()\n\n        self.cnn_1 = nn.Conv2d(in_channels, out_channels, kernel, stride, padding=1)\n        self.cnn_2 = nn.Conv2d(out_channels, out_channels, kernel, stride, padding=1)\n        \n        self.dropout_1 = nn.Dropout(drop_rate)\n        self.dropout_2 = nn.Dropout(drop_rate)\n        \n        self.layer_norm_1 = LayerNorm(n_features)\n        self.layer_norm_2 = LayerNorm(n_features)\n\n    \n    def forward(self, x):\n        skip = x\n\n        # 1st stage\n        x = self.layer_norm_1(x)\n        x = F.relu(x)\n        x = self.dropout_1(x)\n        x = self.cnn_1(x)\n\n        # 2nd stage\n        x = self.layer_norm_2(x)\n        x = F.relu(x)\n        x = self.dropout_2(x)\n        x = self.cnn_2(x)\n    \n        x += skip\n        return x\n\n\nclass BiGRU(nn.Module):\n\n    def __init__(self, rnn_dim, hidden_size, drop_rate, batch_first):\n        super(BiGRU, self).__init__()\n\n        self.gru = nn.GRU(\n            input_size=rnn_dim, hidden_size=hidden_size,\n            num_layers=1, batch_first=batch_first, bidirectional=True)\n        self.layer_norm = nn.LayerNorm(rnn_dim)\n        self.dropout = nn.Dropout(drop_rate)\n    \n    def forward(self, x):\n        \"\"\"\n        Input shape: [batch, seq_len, n_features]\n        \"\"\"\n        x = self.layer_norm(x)\n        x = F.relu(x)\n        x, _ = self.gru(x)\n        x = self.dropout(x)\n        return x\n\n\nclass Classifier(nn.Module):\n    def __init__(self, input_dim, hidden_dim, output_dim, drop_rate):\n        super(Classifier, self).__init__()\n        self.linear_1 = nn.Linear(input_dim, hidden_dim)\n        self.linear_2 = nn.Linear(hidden_dim, output_dim)\n        self.dropout = nn.Dropout(drop_rate)\n\n    def forward(self, x):\n        x = self.linear_1(x)\n        x = F.relu(x)\n        x = self.dropout(x)\n        x = self.linear_2(x)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T14:48:36.276223Z","iopub.execute_input":"2025-04-08T14:48:36.276578Z","iopub.status.idle":"2025-04-08T14:48:36.286080Z","shell.execute_reply.started":"2025-04-08T14:48:36.276542Z","shell.execute_reply":"2025-04-08T14:48:36.285138Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# First model architecture for this ASR project - A variation of the DeepSpeech Model\nclass CustomModel1(nn.Module):\n    \n    def __init__(self, n_cnn, n_rnn, rnn_dim, n_features, n_class, stride=2, drop_rate=0.2):\n        super(CustomModel1, self).__init__()\n        n_features = n_features // 2\n\n        # init conv2d layer\n        self.init_cnn = nn.Conv2d(1, 32, 3, stride=(2,stride), padding=1)\n\n        # 1st stage: ResNet blocks\n        self.stage_1 = nn.Sequential(\n            *[ResNetInv(32, 32, n_features=n_features, kernel=3, stride=1, drop_rate=drop_rate) \n              for _ in range(n_cnn)])\n\n        # linear adapter\n        self.fc_adapter = nn.Linear(n_features*32, rnn_dim)\n\n        # bi-rnn layers\n        self.stage_2 = nn.Sequential(\n            *[BiGRU(rnn_dim=rnn_dim if layer==0 else rnn_dim*2, \n                    hidden_size=rnn_dim, \n                    drop_rate=drop_rate, \n                    batch_first=True)\n            for layer in range(n_rnn)])\n\n        # linear classifier\n        self.classifier = Classifier(rnn_dim*2, rnn_dim, n_class, drop_rate)\n\n    def forward(self, x):\n        x = self.init_cnn(x)\n\n        # Inverse Resnet\n        x = self.stage_1(x)\n\n        # linear adapter\n        shape = x.shape\n        x = x.view(shape[0], shape[1]*shape[2], shape[3]) # (batch, features, time)\n        x = x.transpose(1, 2) # (batch, time, features)\n        x = self.fc_adapter(x)\n\n        # Bi-GRU\n        x = self.stage_2(x)\n\n        # Classifier\n        x = self.classifier(x)\n\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T14:48:36.286993Z","iopub.execute_input":"2025-04-08T14:48:36.287253Z","iopub.status.idle":"2025-04-08T14:48:36.303353Z","shell.execute_reply.started":"2025-04-08T14:48:36.287224Z","shell.execute_reply":"2025-04-08T14:48:36.302453Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"cm1 = CustomModel1(n_cnn=3,\n                             n_rnn=5, \n                             rnn_dim=512, \n                             n_features=n_features, \n                             n_class=word_encoding_model.n_class,\n                             stride=stride,\n                             drop_rate=0.2).to(device)\n\ntot_params = sum([p.numel() for p in cm1.parameters()])\nmodel_name=\"custom model 1\"\nprint(f\"Number of parameters: {tot_params}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T14:48:36.304273Z","iopub.execute_input":"2025-04-08T14:48:36.304497Z","iopub.status.idle":"2025-04-08T14:48:36.780476Z","shell.execute_reply.started":"2025-04-08T14:48:36.304467Z","shell.execute_reply":"2025-04-08T14:48:36.779582Z"}},"outputs":[{"name":"stdout","text":"Number of parameters: 23705373\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"model_to_train = cm1\nadamW = optim.AdamW(model_to_train.parameters(), lr)\nctc_loss = nn.CTCLoss(blank=word_encoding_model.blank_id).to(device)\none_cycle_lr = optim.lr_scheduler.OneCycleLR(adamW,\n                                             max_lr=lr,\n                                             steps_per_epoch=int(len(train_loader)),\n                                             epochs=epochs,\n                                             anneal_strategy=\"linear\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T14:48:36.781277Z","iopub.execute_input":"2025-04-08T14:48:36.781487Z","iopub.status.idle":"2025-04-08T14:48:38.599899Z","shell.execute_reply.started":"2025-04-08T14:48:36.781469Z","shell.execute_reply":"2025-04-08T14:48:38.599226Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"def train(epoch, dataset_loader, model, optimizer, scheduler, fn_loss):\n    print(f\"Traininig... (e={epoch})\")\n    \n    # Train mode ON\n    model.train()\n    total_train_loss = 0  #tracking loss\n    n_samples = int(len(dataset_loader.dataset))\n\n    for idx, audio_data in enumerate(dataset_loader):\n        \n        # Get audio data with shape [batch, 1, n_features, seq_len]\n        spectrograms, indices, len_spectrograms, len_indices = audio_data\n        spectrograms, indices = spectrograms.to(device), indices.to(device)\n\n        optimizer.zero_grad()\n\n        # Forward pass\n        out = model(spectrograms)\n        out = F.log_softmax(out, dim=2)\n        out = out.transpose(0, 1)\n        \n        # Backward pass\n        loss = fn_loss(out, indices, len_spectrograms, len_indices)\n        loss.backward()\n\n        # Step\n        optimizer.step()\n        scheduler.step()\n\n        total_train_loss += loss.item()\n        \n\n        # Log\n        if idx % 20 == 0 or idx == n_samples:\n            print(\"Epoch: {}, [{}/{}], Loss: {:.6f}\".format(\n                epoch, \n                idx*len(spectrograms), \n                n_samples,\n                loss.item()))\n\n    avg_train_loss = total_train_loss/n_samples\n    return avg_train_loss\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T14:48:38.600684Z","iopub.execute_input":"2025-04-08T14:48:38.600997Z","iopub.status.idle":"2025-04-08T14:48:38.606810Z","shell.execute_reply.started":"2025-04-08T14:48:38.600976Z","shell.execute_reply":"2025-04-08T14:48:38.605942Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# Computes Word Error Rate\ndef compute_wer(hypothesis, reference):\n    hypothesis_words = hypothesis.split()\n    reference_words = reference.split()\n    \n    wer = Levenshtein.distance(hypothesis_words, reference_words) / len(reference_words)\n    return wer\n\n# Computes Character Error Rate\ndef compute_cer(hypothesis, reference):\n\n    cer = Levenshtein.distance(hypothesis, reference) / len(reference)\n    return cer\n\n#     Calculates CER for each hyp-ref pair, and returns the average\ndef avg_cer(batch_hyp, batch_ref):\n    batch_size = len(batch_ref)\n    out = []\n    for i in range(batch_size):\n        out.append(compute_cer(batch_hyp[i], batch_ref[i]))\n    \n    return sum(out) / batch_size\n\n#     Calculates WER for each hyp-ref pair, and returns the average\ndef avg_wer(batch_hyp, batch_ref):\n    batch_size = len(batch_ref)\n    out = []\n    for i in range(batch_size):\n        out.append(compute_wer(batch_hyp[i], batch_ref[i]))\n    \n    return sum(out) / batch_size","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T14:48:38.607778Z","iopub.execute_input":"2025-04-08T14:48:38.608079Z","iopub.status.idle":"2025-04-08T14:48:38.626172Z","shell.execute_reply.started":"2025-04-08T14:48:38.608046Z","shell.execute_reply":"2025-04-08T14:48:38.625442Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"def decode_prob(prob, word_encoding_model):\n    \"\"\"\n    Decodes (a batch of) log-probabilities\n    into characters.\n    prob -> shape (e.g.) [16, 650, 29]\n    \"\"\"\n    prob = torch.transpose(prob, 0, 1)\n    arg_maxes = torch.argmax(prob, dim=-1) # [16, 650]\n    decodes = []\n\n    for i, args in enumerate(arg_maxes):\n        decode = []\n        for j, index in enumerate(args):\n             # ignore blank id\n            if index == word_encoding_model.blank_id:\n                continue\n            # avoid repetitions\n            if j != 0 and index == args[j-1]:\n                continue\n            decode.append(index.item())\n        decodes.append(word_encoding_model.int_to_text(decode))\n    return decodes\n\n\ndef decode_labels(indices, len_indices, word_encoding_model):\n    \"\"\"\n    Decodes (a batch of) ids into characters.\n    indices -> shape: [32, 300]\n    len_indices -> shape: [32]\n    word_model -> tool to convert idx into chars\n    \"\"\"\n    out = []\n    for i, ids in enumerate(indices):\n        len_ids = len_indices[i]\n        unpad_ids = ids[:len_ids]\n        out.append(word_encoding_model.int_to_text(unpad_ids.tolist()))\n    return out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T14:48:38.626935Z","iopub.execute_input":"2025-04-08T14:48:38.627136Z","iopub.status.idle":"2025-04-08T14:48:38.643992Z","shell.execute_reply.started":"2025-04-08T14:48:38.627118Z","shell.execute_reply":"2025-04-08T14:48:38.643300Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"def test(epoch, dataset_name, dataset_loader, model, optimizer, fn_loss, debug=False):\n    print(f\"Testing on {dataset_name} (epoch={epoch})\")\n    model.eval()\n\n    total_loss = 0\n    wer_list = []\n    cer_list = []\n\n    n_batch = int(len(dataset_loader))\n\n    with torch.no_grad():\n        for idx, audio_data in enumerate(dataset_loader):\n        \n            # Get audio data\n            spectrograms, indices, len_spectrograms, len_indices = audio_data\n            spectrograms, indices = spectrograms.to(device), indices.to(device)\n\n            optimizer.zero_grad()\n            \n            # Forward pass\n            out = model(spectrograms)\n            out = F.log_softmax(out, dim=2)\n            out = out.transpose(0, 1)\n\n            # Compute loss\n            loss = fn_loss(out, indices, len_spectrograms, len_indices)\n            total_loss += loss.item() / n_batch\n\n            # Metrics\n            decode_hypothesis = decode_prob(out, word_encoding_model)\n            decode_reference = decode_labels(indices, len_indices, word_encoding_model)\n\n            wer_list.append(avg_wer(decode_hypothesis, decode_reference))\n            cer_list.append(avg_cer(decode_hypothesis, decode_reference))\n            \n            \n    print(f\"Loss: {total_loss:.6f}\")\n    print(f\"WER: {sum(wer_list)/len(wer_list):.4f}\")\n    print(f\"CER: {sum(cer_list)/len(cer_list):.4f}\")\n\n    avg_test_wer = sum(wer_list) / len(wer_list)\n    avg_test_cer = sum(cer_list) / len(cer_list)\n\n    return total_loss, avg_test_wer, avg_test_cer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T14:48:38.644727Z","iopub.execute_input":"2025-04-08T14:48:38.644973Z","iopub.status.idle":"2025-04-08T14:48:38.662326Z","shell.execute_reply.started":"2025-04-08T14:48:38.644954Z","shell.execute_reply":"2025-04-08T14:48:38.661586Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"import time\n\ntrain_loss = []\n# dev_loss = []\n# dev_wer = []\n# dev_cer = []\n\ntotal_training_time = 0 \n\nfor epoch in range(1, epochs+1):\n    #calculate train time\n    training_start = time.time()\n    \n    train_epoch_loss = train(epoch, train_loader, model_to_train, adamW, one_cycle_lr, ctc_loss)\n\n    training_end = time.time()\n\n    training_time = (training_end - training_start)/60  #measuring in mins\n    total_training_time += training_time\n    \n    print(f\"Epoch {epoch} training time: {training_time:.2f} minutes\")\n\n    train_loss.append(train_epoch_loss)\n\n    # #dev\n    # dev_epoch_loss, dev_epoch_wer, dev_epoch_cer = test(epoch, \"dev-clean\", dev_clean_loader, model_to_train, adamW, ctc_loss)\n    # dev_loss.append(dev_epoch_loss)\n    # dev_wer.append(dev_epoch_wer)\n    # dev_cer.append(dev_epoch_cer)\n\n\navg_training_time = total_training_time / epochs\nprint(f\"\\nTotal training time: {total_training_time:.2f} minutes\")\nprint(f\"\\nAverage training time: {avg_training_time:.2f} minutes\")\n\n#Test set\ntest_epoch_loss, test_epoch_wer, test_epoch_cer = test(epoch, \"test-clean\", test_clean_loader, model_to_train, adamW, ctc_loss)\nprint(f\"Test Loss: {test_epoch_loss:.4f}\")\nprint(f\"Test WER: {test_epoch_wer:.4f}\")\nprint(f\"Test CER: {test_epoch_cer:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T14:48:38.663057Z","iopub.execute_input":"2025-04-08T14:48:38.663294Z","iopub.status.idle":"2025-04-08T19:01:33.702656Z","shell.execute_reply.started":"2025-04-08T14:48:38.663274Z","shell.execute_reply":"2025-04-08T19:01:33.701746Z"}},"outputs":[{"name":"stdout","text":"Traininig... (e=1)\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 1, [0/28539], Loss: 5.665479\nEpoch: 1, [320/28539], Loss: 4.009433\nEpoch: 1, [640/28539], Loss: 3.151609\nEpoch: 1, [960/28539], Loss: 3.008581\nEpoch: 1, [1280/28539], Loss: 2.922391\nEpoch: 1, [1600/28539], Loss: 2.870008\nEpoch: 1, [1920/28539], Loss: 3.157031\nEpoch: 1, [2240/28539], Loss: 2.892590\nEpoch: 1, [2560/28539], Loss: 2.871378\nEpoch: 1, [2880/28539], Loss: 2.911410\nEpoch: 1, [3200/28539], Loss: 2.860404\nEpoch: 1, [3520/28539], Loss: 2.839425\nEpoch: 1, [3840/28539], Loss: 2.867253\nEpoch: 1, [4160/28539], Loss: 2.848605\nEpoch: 1, [4480/28539], Loss: 2.887779\nEpoch: 1, [4800/28539], Loss: 2.930635\nEpoch: 1, [5120/28539], Loss: 2.884335\nEpoch: 1, [5440/28539], Loss: 2.886437\nEpoch: 1, [5760/28539], Loss: 2.828763\nEpoch: 1, [6080/28539], Loss: 2.839197\nEpoch: 1, [6400/28539], Loss: 2.834445\nEpoch: 1, [6720/28539], Loss: 2.863348\nEpoch: 1, [7040/28539], Loss: 2.907986\nEpoch: 1, [7360/28539], Loss: 2.830158\nEpoch: 1, [7680/28539], Loss: 2.876533\nEpoch: 1, [8000/28539], Loss: 2.820088\nEpoch: 1, [8320/28539], Loss: 2.820335\nEpoch: 1, [8640/28539], Loss: 2.894398\nEpoch: 1, [8960/28539], Loss: 2.905712\nEpoch: 1, [9280/28539], Loss: 2.871009\nEpoch: 1, [9600/28539], Loss: 2.898998\nEpoch: 1, [9920/28539], Loss: 2.877893\nEpoch: 1, [10240/28539], Loss: 2.810635\nEpoch: 1, [10560/28539], Loss: 2.847806\nEpoch: 1, [10880/28539], Loss: 2.878963\nEpoch: 1, [11200/28539], Loss: 2.985605\nEpoch: 1, [11520/28539], Loss: 2.885151\nEpoch: 1, [11840/28539], Loss: 2.859125\nEpoch: 1, [12160/28539], Loss: 2.970262\nEpoch: 1, [12480/28539], Loss: 2.867836\nEpoch: 1, [12800/28539], Loss: 2.846144\nEpoch: 1, [13120/28539], Loss: 2.857467\nEpoch: 1, [13440/28539], Loss: 2.912486\nEpoch: 1, [13760/28539], Loss: 2.891701\nEpoch: 1, [14080/28539], Loss: 2.915897\nEpoch: 1, [14400/28539], Loss: 2.874111\nEpoch: 1, [14720/28539], Loss: 2.919044\nEpoch: 1, [15040/28539], Loss: 2.899576\nEpoch: 1, [15360/28539], Loss: 2.907963\nEpoch: 1, [15680/28539], Loss: 2.918243\nEpoch: 1, [16000/28539], Loss: 2.826252\nEpoch: 1, [16320/28539], Loss: 2.887541\nEpoch: 1, [16640/28539], Loss: 2.810359\nEpoch: 1, [16960/28539], Loss: 2.882331\nEpoch: 1, [17280/28539], Loss: 2.885494\nEpoch: 1, [17600/28539], Loss: 2.858616\nEpoch: 1, [17920/28539], Loss: 2.867177\nEpoch: 1, [18240/28539], Loss: 2.844029\nEpoch: 1, [18560/28539], Loss: 2.852336\nEpoch: 1, [18880/28539], Loss: 2.857462\nEpoch: 1, [19200/28539], Loss: 2.896211\nEpoch: 1, [19520/28539], Loss: 2.868605\nEpoch: 1, [19840/28539], Loss: 2.884669\nEpoch: 1, [20160/28539], Loss: 2.829117\nEpoch: 1, [20480/28539], Loss: 2.851677\nEpoch: 1, [20800/28539], Loss: 2.914944\nEpoch: 1, [21120/28539], Loss: 2.895322\nEpoch: 1, [21440/28539], Loss: 2.869887\nEpoch: 1, [21760/28539], Loss: 2.857844\nEpoch: 1, [22080/28539], Loss: 2.817659\nEpoch: 1, [22400/28539], Loss: 2.823115\nEpoch: 1, [22720/28539], Loss: 2.861193\nEpoch: 1, [23040/28539], Loss: 2.825011\nEpoch: 1, [23360/28539], Loss: 2.796106\nEpoch: 1, [23680/28539], Loss: 2.863802\nEpoch: 1, [24000/28539], Loss: 2.831367\nEpoch: 1, [24320/28539], Loss: 2.941901\nEpoch: 1, [24640/28539], Loss: 2.847656\nEpoch: 1, [24960/28539], Loss: 2.863600\nEpoch: 1, [25280/28539], Loss: 2.839150\nEpoch: 1, [25600/28539], Loss: 2.797380\nEpoch: 1, [25920/28539], Loss: 2.827528\nEpoch: 1, [26240/28539], Loss: 2.895278\nEpoch: 1, [26560/28539], Loss: 2.830796\nEpoch: 1, [26880/28539], Loss: 2.799014\nEpoch: 1, [27200/28539], Loss: 2.829347\nEpoch: 1, [27520/28539], Loss: 2.836456\nEpoch: 1, [27840/28539], Loss: 2.800195\nEpoch: 1, [28160/28539], Loss: 2.806853\nEpoch: 1, [28480/28539], Loss: 2.829080\nEpoch 1 training time: 29.50 minutes\nTraininig... (e=2)\nEpoch: 2, [0/28539], Loss: 2.895672\nEpoch: 2, [320/28539], Loss: 2.864467\nEpoch: 2, [640/28539], Loss: 2.843418\nEpoch: 2, [960/28539], Loss: 2.905463\nEpoch: 2, [1280/28539], Loss: 2.823041\nEpoch: 2, [1600/28539], Loss: 2.766179\nEpoch: 2, [1920/28539], Loss: 3.023424\nEpoch: 2, [2240/28539], Loss: 2.865232\nEpoch: 2, [2560/28539], Loss: 2.822534\nEpoch: 2, [2880/28539], Loss: 2.827808\nEpoch: 2, [3200/28539], Loss: 2.826761\nEpoch: 2, [3520/28539], Loss: 2.755029\nEpoch: 2, [3840/28539], Loss: 2.794727\nEpoch: 2, [4160/28539], Loss: 2.732108\nEpoch: 2, [4480/28539], Loss: 2.785852\nEpoch: 2, [4800/28539], Loss: 2.730131\nEpoch: 2, [5120/28539], Loss: 2.769863\nEpoch: 2, [5440/28539], Loss: 2.646461\nEpoch: 2, [5760/28539], Loss: 2.581073\nEpoch: 2, [6080/28539], Loss: 2.555549\nEpoch: 2, [6400/28539], Loss: 2.564348\nEpoch: 2, [6720/28539], Loss: 2.533573\nEpoch: 2, [7040/28539], Loss: 2.536186\nEpoch: 2, [7360/28539], Loss: 2.485118\nEpoch: 2, [7680/28539], Loss: 2.504779\nEpoch: 2, [8000/28539], Loss: 2.348806\nEpoch: 2, [8320/28539], Loss: 2.421129\nEpoch: 2, [8640/28539], Loss: 2.406783\nEpoch: 2, [8960/28539], Loss: 2.512324\nEpoch: 2, [9280/28539], Loss: 2.428333\nEpoch: 2, [9600/28539], Loss: 2.480750\nEpoch: 2, [9920/28539], Loss: 2.413090\nEpoch: 2, [10240/28539], Loss: 2.322537\nEpoch: 2, [10560/28539], Loss: 2.438087\nEpoch: 2, [10880/28539], Loss: 2.279735\nEpoch: 2, [11200/28539], Loss: 2.438773\nEpoch: 2, [11520/28539], Loss: 2.304117\nEpoch: 2, [11840/28539], Loss: 2.340934\nEpoch: 2, [12160/28539], Loss: 2.414512\nEpoch: 2, [12480/28539], Loss: 2.238579\nEpoch: 2, [12800/28539], Loss: 2.217923\nEpoch: 2, [13120/28539], Loss: 2.249793\nEpoch: 2, [13440/28539], Loss: 2.287065\nEpoch: 2, [13760/28539], Loss: 2.337546\nEpoch: 2, [14080/28539], Loss: 2.184780\nEpoch: 2, [14400/28539], Loss: 2.134811\nEpoch: 2, [14720/28539], Loss: 2.217323\nEpoch: 2, [15040/28539], Loss: 2.366109\nEpoch: 2, [15360/28539], Loss: 2.332625\nEpoch: 2, [15680/28539], Loss: 2.216107\nEpoch: 2, [16000/28539], Loss: 2.162941\nEpoch: 2, [16320/28539], Loss: 2.322244\nEpoch: 2, [16640/28539], Loss: 2.000157\nEpoch: 2, [16960/28539], Loss: 2.060606\nEpoch: 2, [17280/28539], Loss: 2.208302\nEpoch: 2, [17600/28539], Loss: 2.180293\nEpoch: 2, [17920/28539], Loss: 2.049108\nEpoch: 2, [18240/28539], Loss: 2.207452\nEpoch: 2, [18560/28539], Loss: 1.921483\nEpoch: 2, [18880/28539], Loss: 2.329750\nEpoch: 2, [19200/28539], Loss: 2.236635\nEpoch: 2, [19520/28539], Loss: 1.930185\nEpoch: 2, [19840/28539], Loss: 2.017458\nEpoch: 2, [20160/28539], Loss: 2.089098\nEpoch: 2, [20480/28539], Loss: 2.028738\nEpoch: 2, [20800/28539], Loss: 2.216756\nEpoch: 2, [21120/28539], Loss: 1.972878\nEpoch: 2, [21440/28539], Loss: 2.194090\nEpoch: 2, [21760/28539], Loss: 1.836360\nEpoch: 2, [22080/28539], Loss: 1.891388\nEpoch: 2, [22400/28539], Loss: 1.855684\nEpoch: 2, [22720/28539], Loss: 2.092426\nEpoch: 2, [23040/28539], Loss: 2.006441\nEpoch: 2, [23360/28539], Loss: 1.867172\nEpoch: 2, [23680/28539], Loss: 1.977636\nEpoch: 2, [24000/28539], Loss: 1.773994\nEpoch: 2, [24320/28539], Loss: 1.869669\nEpoch: 2, [24640/28539], Loss: 1.776105\nEpoch: 2, [24960/28539], Loss: 1.755037\nEpoch: 2, [25280/28539], Loss: 2.103818\nEpoch: 2, [25600/28539], Loss: 1.697589\nEpoch: 2, [25920/28539], Loss: 1.687504\nEpoch: 2, [26240/28539], Loss: 2.044826\nEpoch: 2, [26560/28539], Loss: 1.856390\nEpoch: 2, [26880/28539], Loss: 2.003865\nEpoch: 2, [27200/28539], Loss: 1.822463\nEpoch: 2, [27520/28539], Loss: 1.616561\nEpoch: 2, [27840/28539], Loss: 1.531019\nEpoch: 2, [28160/28539], Loss: 1.858963\nEpoch: 2, [28480/28539], Loss: 1.697101\nEpoch 2 training time: 24.63 minutes\nTraininig... (e=3)\nEpoch: 3, [0/28539], Loss: 1.852296\nEpoch: 3, [320/28539], Loss: 1.837419\nEpoch: 3, [640/28539], Loss: 1.794921\nEpoch: 3, [960/28539], Loss: 2.251502\nEpoch: 3, [1280/28539], Loss: 1.786604\nEpoch: 3, [1600/28539], Loss: 1.449183\nEpoch: 3, [1920/28539], Loss: 2.290871\nEpoch: 3, [2240/28539], Loss: 1.960281\nEpoch: 3, [2560/28539], Loss: 1.725949\nEpoch: 3, [2880/28539], Loss: 1.774900\nEpoch: 3, [3200/28539], Loss: 1.825960\nEpoch: 3, [3520/28539], Loss: 1.608184\nEpoch: 3, [3840/28539], Loss: 1.703827\nEpoch: 3, [4160/28539], Loss: 1.562767\nEpoch: 3, [4480/28539], Loss: 1.613076\nEpoch: 3, [4800/28539], Loss: 1.716670\nEpoch: 3, [5120/28539], Loss: 1.680327\nEpoch: 3, [5440/28539], Loss: 1.647483\nEpoch: 3, [5760/28539], Loss: 1.631391\nEpoch: 3, [6080/28539], Loss: 1.447611\nEpoch: 3, [6400/28539], Loss: 1.680340\nEpoch: 3, [6720/28539], Loss: 1.640167\nEpoch: 3, [7040/28539], Loss: 1.641731\nEpoch: 3, [7360/28539], Loss: 1.364951\nEpoch: 3, [7680/28539], Loss: 1.531498\nEpoch: 3, [8000/28539], Loss: 1.488349\nEpoch: 3, [8320/28539], Loss: 1.534891\nEpoch: 3, [8640/28539], Loss: 1.557991\nEpoch: 3, [8960/28539], Loss: 1.735069\nEpoch: 3, [9280/28539], Loss: 1.610666\nEpoch: 3, [9600/28539], Loss: 1.729167\nEpoch: 3, [9920/28539], Loss: 1.664199\nEpoch: 3, [10240/28539], Loss: 1.563950\nEpoch: 3, [10560/28539], Loss: 1.732080\nEpoch: 3, [10880/28539], Loss: 1.457638\nEpoch: 3, [11200/28539], Loss: 1.655770\nEpoch: 3, [11520/28539], Loss: 1.527872\nEpoch: 3, [11840/28539], Loss: 1.645024\nEpoch: 3, [12160/28539], Loss: 1.631553\nEpoch: 3, [12480/28539], Loss: 1.429045\nEpoch: 3, [12800/28539], Loss: 1.561544\nEpoch: 3, [13120/28539], Loss: 1.470212\nEpoch: 3, [13440/28539], Loss: 1.474320\nEpoch: 3, [13760/28539], Loss: 1.696467\nEpoch: 3, [14080/28539], Loss: 1.408707\nEpoch: 3, [14400/28539], Loss: 1.355709\nEpoch: 3, [14720/28539], Loss: 1.653479\nEpoch: 3, [15040/28539], Loss: 1.669165\nEpoch: 3, [15360/28539], Loss: 1.480671\nEpoch: 3, [15680/28539], Loss: 1.554641\nEpoch: 3, [16000/28539], Loss: 1.388669\nEpoch: 3, [16320/28539], Loss: 1.719911\nEpoch: 3, [16640/28539], Loss: 1.363518\nEpoch: 3, [16960/28539], Loss: 1.349894\nEpoch: 3, [17280/28539], Loss: 1.541502\nEpoch: 3, [17600/28539], Loss: 1.586111\nEpoch: 3, [17920/28539], Loss: 1.307103\nEpoch: 3, [18240/28539], Loss: 1.571823\nEpoch: 3, [18560/28539], Loss: 1.222445\nEpoch: 3, [18880/28539], Loss: 1.624252\nEpoch: 3, [19200/28539], Loss: 1.469971\nEpoch: 3, [19520/28539], Loss: 1.351806\nEpoch: 3, [19840/28539], Loss: 1.380631\nEpoch: 3, [20160/28539], Loss: 1.511820\nEpoch: 3, [20480/28539], Loss: 1.385425\nEpoch: 3, [20800/28539], Loss: 1.821239\nEpoch: 3, [21120/28539], Loss: 1.502722\nEpoch: 3, [21440/28539], Loss: 1.631938\nEpoch: 3, [21760/28539], Loss: 1.210631\nEpoch: 3, [22080/28539], Loss: 1.386700\nEpoch: 3, [22400/28539], Loss: 1.272754\nEpoch: 3, [22720/28539], Loss: 1.555087\nEpoch: 3, [23040/28539], Loss: 1.521935\nEpoch: 3, [23360/28539], Loss: 1.329137\nEpoch: 3, [23680/28539], Loss: 1.400638\nEpoch: 3, [24000/28539], Loss: 1.276109\nEpoch: 3, [24320/28539], Loss: 1.362198\nEpoch: 3, [24640/28539], Loss: 1.225445\nEpoch: 3, [24960/28539], Loss: 1.188802\nEpoch: 3, [25280/28539], Loss: 1.592743\nEpoch: 3, [25600/28539], Loss: 1.190134\nEpoch: 3, [25920/28539], Loss: 1.135018\nEpoch: 3, [26240/28539], Loss: 1.662626\nEpoch: 3, [26560/28539], Loss: 1.336645\nEpoch: 3, [26880/28539], Loss: 1.490611\nEpoch: 3, [27200/28539], Loss: 1.373785\nEpoch: 3, [27520/28539], Loss: 1.254153\nEpoch: 3, [27840/28539], Loss: 1.019098\nEpoch: 3, [28160/28539], Loss: 1.448170\nEpoch: 3, [28480/28539], Loss: 1.159563\nEpoch 3 training time: 24.53 minutes\nTraininig... (e=4)\nEpoch: 4, [0/28539], Loss: 1.373623\nEpoch: 4, [320/28539], Loss: 1.201013\nEpoch: 4, [640/28539], Loss: 1.210281\nEpoch: 4, [960/28539], Loss: 1.872318\nEpoch: 4, [1280/28539], Loss: 1.289268\nEpoch: 4, [1600/28539], Loss: 1.053279\nEpoch: 4, [1920/28539], Loss: 2.150895\nEpoch: 4, [2240/28539], Loss: 1.576476\nEpoch: 4, [2560/28539], Loss: 1.229354\nEpoch: 4, [2880/28539], Loss: 1.350640\nEpoch: 4, [3200/28539], Loss: 1.317143\nEpoch: 4, [3520/28539], Loss: 1.183926\nEpoch: 4, [3840/28539], Loss: 1.268199\nEpoch: 4, [4160/28539], Loss: 1.027354\nEpoch: 4, [4480/28539], Loss: 1.164928\nEpoch: 4, [4800/28539], Loss: 1.214921\nEpoch: 4, [5120/28539], Loss: 1.201370\nEpoch: 4, [5440/28539], Loss: 1.232687\nEpoch: 4, [5760/28539], Loss: 1.299904\nEpoch: 4, [6080/28539], Loss: 1.092294\nEpoch: 4, [6400/28539], Loss: 1.354972\nEpoch: 4, [6720/28539], Loss: 1.157998\nEpoch: 4, [7040/28539], Loss: 1.230980\nEpoch: 4, [7360/28539], Loss: 1.031835\nEpoch: 4, [7680/28539], Loss: 1.171212\nEpoch: 4, [8000/28539], Loss: 1.028336\nEpoch: 4, [8320/28539], Loss: 1.126072\nEpoch: 4, [8640/28539], Loss: 1.217133\nEpoch: 4, [8960/28539], Loss: 1.378157\nEpoch: 4, [9280/28539], Loss: 1.179026\nEpoch: 4, [9600/28539], Loss: 1.438377\nEpoch: 4, [9920/28539], Loss: 1.337521\nEpoch: 4, [10240/28539], Loss: 1.224114\nEpoch: 4, [10560/28539], Loss: 1.506606\nEpoch: 4, [10880/28539], Loss: 1.129319\nEpoch: 4, [11200/28539], Loss: 1.301347\nEpoch: 4, [11520/28539], Loss: 1.316596\nEpoch: 4, [11840/28539], Loss: 1.337233\nEpoch: 4, [12160/28539], Loss: 1.184488\nEpoch: 4, [12480/28539], Loss: 1.075350\nEpoch: 4, [12800/28539], Loss: 1.209231\nEpoch: 4, [13120/28539], Loss: 1.179787\nEpoch: 4, [13440/28539], Loss: 1.114191\nEpoch: 4, [13760/28539], Loss: 1.404878\nEpoch: 4, [14080/28539], Loss: 0.989912\nEpoch: 4, [14400/28539], Loss: 1.020528\nEpoch: 4, [14720/28539], Loss: 1.338511\nEpoch: 4, [15040/28539], Loss: 1.349748\nEpoch: 4, [15360/28539], Loss: 1.119237\nEpoch: 4, [15680/28539], Loss: 1.212477\nEpoch: 4, [16000/28539], Loss: 1.070380\nEpoch: 4, [16320/28539], Loss: 1.418932\nEpoch: 4, [16640/28539], Loss: 1.065418\nEpoch: 4, [16960/28539], Loss: 0.996612\nEpoch: 4, [17280/28539], Loss: 1.261893\nEpoch: 4, [17600/28539], Loss: 1.275666\nEpoch: 4, [17920/28539], Loss: 1.013170\nEpoch: 4, [18240/28539], Loss: 1.177133\nEpoch: 4, [18560/28539], Loss: 0.916256\nEpoch: 4, [18880/28539], Loss: 1.197743\nEpoch: 4, [19200/28539], Loss: 1.150946\nEpoch: 4, [19520/28539], Loss: 1.068533\nEpoch: 4, [19840/28539], Loss: 1.147999\nEpoch: 4, [20160/28539], Loss: 1.220875\nEpoch: 4, [20480/28539], Loss: 1.102998\nEpoch: 4, [20800/28539], Loss: 1.490957\nEpoch: 4, [21120/28539], Loss: 1.287590\nEpoch: 4, [21440/28539], Loss: 1.271926\nEpoch: 4, [21760/28539], Loss: 0.968897\nEpoch: 4, [22080/28539], Loss: 1.150001\nEpoch: 4, [22400/28539], Loss: 1.031367\nEpoch: 4, [22720/28539], Loss: 1.415142\nEpoch: 4, [23040/28539], Loss: 1.320608\nEpoch: 4, [23360/28539], Loss: 1.168072\nEpoch: 4, [23680/28539], Loss: 1.136612\nEpoch: 4, [24000/28539], Loss: 1.034793\nEpoch: 4, [24320/28539], Loss: 1.138919\nEpoch: 4, [24640/28539], Loss: 0.892950\nEpoch: 4, [24960/28539], Loss: 1.008904\nEpoch: 4, [25280/28539], Loss: 1.375619\nEpoch: 4, [25600/28539], Loss: 0.985206\nEpoch: 4, [25920/28539], Loss: 0.877791\nEpoch: 4, [26240/28539], Loss: 1.474972\nEpoch: 4, [26560/28539], Loss: 1.021418\nEpoch: 4, [26880/28539], Loss: 1.106295\nEpoch: 4, [27200/28539], Loss: 1.079500\nEpoch: 4, [27520/28539], Loss: 1.021753\nEpoch: 4, [27840/28539], Loss: 0.799718\nEpoch: 4, [28160/28539], Loss: 1.229840\nEpoch: 4, [28480/28539], Loss: 0.957805\nEpoch 4 training time: 24.54 minutes\nTraininig... (e=5)\nEpoch: 5, [0/28539], Loss: 1.054240\nEpoch: 5, [320/28539], Loss: 0.942284\nEpoch: 5, [640/28539], Loss: 0.939233\nEpoch: 5, [960/28539], Loss: 1.588054\nEpoch: 5, [1280/28539], Loss: 1.032993\nEpoch: 5, [1600/28539], Loss: 0.803439\nEpoch: 5, [1920/28539], Loss: 1.809170\nEpoch: 5, [2240/28539], Loss: 1.290330\nEpoch: 5, [2560/28539], Loss: 1.021200\nEpoch: 5, [2880/28539], Loss: 1.055669\nEpoch: 5, [3200/28539], Loss: 1.065126\nEpoch: 5, [3520/28539], Loss: 0.902140\nEpoch: 5, [3840/28539], Loss: 1.065717\nEpoch: 5, [4160/28539], Loss: 0.807747\nEpoch: 5, [4480/28539], Loss: 0.950371\nEpoch: 5, [4800/28539], Loss: 0.975077\nEpoch: 5, [5120/28539], Loss: 0.951800\nEpoch: 5, [5440/28539], Loss: 0.970212\nEpoch: 5, [5760/28539], Loss: 1.132928\nEpoch: 5, [6080/28539], Loss: 0.820715\nEpoch: 5, [6400/28539], Loss: 1.117980\nEpoch: 5, [6720/28539], Loss: 0.957060\nEpoch: 5, [7040/28539], Loss: 1.009264\nEpoch: 5, [7360/28539], Loss: 0.845367\nEpoch: 5, [7680/28539], Loss: 1.010738\nEpoch: 5, [8000/28539], Loss: 0.861243\nEpoch: 5, [8320/28539], Loss: 0.924036\nEpoch: 5, [8640/28539], Loss: 1.038692\nEpoch: 5, [8960/28539], Loss: 1.060620\nEpoch: 5, [9280/28539], Loss: 0.996333\nEpoch: 5, [9600/28539], Loss: 1.275670\nEpoch: 5, [9920/28539], Loss: 1.188488\nEpoch: 5, [10240/28539], Loss: 0.995992\nEpoch: 5, [10560/28539], Loss: 1.299018\nEpoch: 5, [10880/28539], Loss: 0.974319\nEpoch: 5, [11200/28539], Loss: 1.105362\nEpoch: 5, [11520/28539], Loss: 1.154363\nEpoch: 5, [11840/28539], Loss: 1.075048\nEpoch: 5, [12160/28539], Loss: 1.003299\nEpoch: 5, [12480/28539], Loss: 0.862714\nEpoch: 5, [12800/28539], Loss: 1.032279\nEpoch: 5, [13120/28539], Loss: 1.031734\nEpoch: 5, [13440/28539], Loss: 0.887354\nEpoch: 5, [13760/28539], Loss: 1.260980\nEpoch: 5, [14080/28539], Loss: 0.811784\nEpoch: 5, [14400/28539], Loss: 0.859579\nEpoch: 5, [14720/28539], Loss: 1.135707\nEpoch: 5, [15040/28539], Loss: 1.166048\nEpoch: 5, [15360/28539], Loss: 0.971533\nEpoch: 5, [15680/28539], Loss: 1.081696\nEpoch: 5, [16000/28539], Loss: 0.752184\nEpoch: 5, [16320/28539], Loss: 1.172013\nEpoch: 5, [16640/28539], Loss: 0.854924\nEpoch: 5, [16960/28539], Loss: 0.818295\nEpoch: 5, [17280/28539], Loss: 1.141843\nEpoch: 5, [17600/28539], Loss: 1.063810\nEpoch: 5, [17920/28539], Loss: 0.851891\nEpoch: 5, [18240/28539], Loss: 0.992936\nEpoch: 5, [18560/28539], Loss: 0.785517\nEpoch: 5, [18880/28539], Loss: 0.994314\nEpoch: 5, [19200/28539], Loss: 0.963450\nEpoch: 5, [19520/28539], Loss: 0.836752\nEpoch: 5, [19840/28539], Loss: 0.905615\nEpoch: 5, [20160/28539], Loss: 1.055827\nEpoch: 5, [20480/28539], Loss: 0.972419\nEpoch: 5, [20800/28539], Loss: 1.362552\nEpoch: 5, [21120/28539], Loss: 1.185655\nEpoch: 5, [21440/28539], Loss: 1.145496\nEpoch: 5, [21760/28539], Loss: 0.816644\nEpoch: 5, [22080/28539], Loss: 0.978620\nEpoch: 5, [22400/28539], Loss: 0.904377\nEpoch: 5, [22720/28539], Loss: 1.224024\nEpoch: 5, [23040/28539], Loss: 1.179317\nEpoch: 5, [23360/28539], Loss: 0.943951\nEpoch: 5, [23680/28539], Loss: 1.016205\nEpoch: 5, [24000/28539], Loss: 0.872717\nEpoch: 5, [24320/28539], Loss: 0.964519\nEpoch: 5, [24640/28539], Loss: 0.785635\nEpoch: 5, [24960/28539], Loss: 0.853239\nEpoch: 5, [25280/28539], Loss: 1.184884\nEpoch: 5, [25600/28539], Loss: 0.818859\nEpoch: 5, [25920/28539], Loss: 0.730307\nEpoch: 5, [26240/28539], Loss: 1.251252\nEpoch: 5, [26560/28539], Loss: 0.797890\nEpoch: 5, [26880/28539], Loss: 0.920645\nEpoch: 5, [27200/28539], Loss: 0.909927\nEpoch: 5, [27520/28539], Loss: 0.929383\nEpoch: 5, [27840/28539], Loss: 0.687602\nEpoch: 5, [28160/28539], Loss: 1.083838\nEpoch: 5, [28480/28539], Loss: 0.863359\nEpoch 5 training time: 24.50 minutes\nTraininig... (e=6)\nEpoch: 6, [0/28539], Loss: 0.907019\nEpoch: 6, [320/28539], Loss: 0.766926\nEpoch: 6, [640/28539], Loss: 0.734554\nEpoch: 6, [960/28539], Loss: 1.516984\nEpoch: 6, [1280/28539], Loss: 0.915117\nEpoch: 6, [1600/28539], Loss: 0.673661\nEpoch: 6, [1920/28539], Loss: 1.656141\nEpoch: 6, [2240/28539], Loss: 1.204266\nEpoch: 6, [2560/28539], Loss: 0.844622\nEpoch: 6, [2880/28539], Loss: 0.939441\nEpoch: 6, [3200/28539], Loss: 0.908688\nEpoch: 6, [3520/28539], Loss: 0.805879\nEpoch: 6, [3840/28539], Loss: 0.932752\nEpoch: 6, [4160/28539], Loss: 0.684819\nEpoch: 6, [4480/28539], Loss: 0.829315\nEpoch: 6, [4800/28539], Loss: 0.869820\nEpoch: 6, [5120/28539], Loss: 0.857281\nEpoch: 6, [5440/28539], Loss: 0.875829\nEpoch: 6, [5760/28539], Loss: 0.884573\nEpoch: 6, [6080/28539], Loss: 0.699501\nEpoch: 6, [6400/28539], Loss: 0.963179\nEpoch: 6, [6720/28539], Loss: 0.764103\nEpoch: 6, [7040/28539], Loss: 1.003005\nEpoch: 6, [7360/28539], Loss: 0.677910\nEpoch: 6, [7680/28539], Loss: 0.918595\nEpoch: 6, [8000/28539], Loss: 0.720410\nEpoch: 6, [8320/28539], Loss: 0.806724\nEpoch: 6, [8640/28539], Loss: 0.984980\nEpoch: 6, [8960/28539], Loss: 0.922056\nEpoch: 6, [9280/28539], Loss: 0.879122\nEpoch: 6, [9600/28539], Loss: 1.176424\nEpoch: 6, [9920/28539], Loss: 0.996166\nEpoch: 6, [10240/28539], Loss: 0.872104\nEpoch: 6, [10560/28539], Loss: 1.250413\nEpoch: 6, [10880/28539], Loss: 0.851502\nEpoch: 6, [11200/28539], Loss: 0.922019\nEpoch: 6, [11520/28539], Loss: 0.977946\nEpoch: 6, [11840/28539], Loss: 0.979079\nEpoch: 6, [12160/28539], Loss: 0.837480\nEpoch: 6, [12480/28539], Loss: 0.778376\nEpoch: 6, [12800/28539], Loss: 0.911720\nEpoch: 6, [13120/28539], Loss: 0.877679\nEpoch: 6, [13440/28539], Loss: 0.772974\nEpoch: 6, [13760/28539], Loss: 1.154890\nEpoch: 6, [14080/28539], Loss: 0.717283\nEpoch: 6, [14400/28539], Loss: 0.750733\nEpoch: 6, [14720/28539], Loss: 0.969809\nEpoch: 6, [15040/28539], Loss: 0.990947\nEpoch: 6, [15360/28539], Loss: 0.930783\nEpoch: 6, [15680/28539], Loss: 0.934190\nEpoch: 6, [16000/28539], Loss: 0.636368\nEpoch: 6, [16320/28539], Loss: 1.067239\nEpoch: 6, [16640/28539], Loss: 0.758125\nEpoch: 6, [16960/28539], Loss: 0.746129\nEpoch: 6, [17280/28539], Loss: 1.013933\nEpoch: 6, [17600/28539], Loss: 0.964307\nEpoch: 6, [17920/28539], Loss: 0.789323\nEpoch: 6, [18240/28539], Loss: 0.908967\nEpoch: 6, [18560/28539], Loss: 0.741727\nEpoch: 6, [18880/28539], Loss: 0.828785\nEpoch: 6, [19200/28539], Loss: 0.831340\nEpoch: 6, [19520/28539], Loss: 0.753063\nEpoch: 6, [19840/28539], Loss: 0.847613\nEpoch: 6, [20160/28539], Loss: 0.948788\nEpoch: 6, [20480/28539], Loss: 0.849242\nEpoch: 6, [20800/28539], Loss: 1.183113\nEpoch: 6, [21120/28539], Loss: 1.049688\nEpoch: 6, [21440/28539], Loss: 1.025790\nEpoch: 6, [21760/28539], Loss: 0.746881\nEpoch: 6, [22080/28539], Loss: 0.930912\nEpoch: 6, [22400/28539], Loss: 0.758441\nEpoch: 6, [22720/28539], Loss: 1.157269\nEpoch: 6, [23040/28539], Loss: 1.076563\nEpoch: 6, [23360/28539], Loss: 0.867821\nEpoch: 6, [23680/28539], Loss: 0.903014\nEpoch: 6, [24000/28539], Loss: 0.801863\nEpoch: 6, [24320/28539], Loss: 0.824536\nEpoch: 6, [24640/28539], Loss: 0.692498\nEpoch: 6, [24960/28539], Loss: 0.775566\nEpoch: 6, [25280/28539], Loss: 1.088428\nEpoch: 6, [25600/28539], Loss: 0.765945\nEpoch: 6, [25920/28539], Loss: 0.646481\nEpoch: 6, [26240/28539], Loss: 1.088744\nEpoch: 6, [26560/28539], Loss: 0.647986\nEpoch: 6, [26880/28539], Loss: 0.809831\nEpoch: 6, [27200/28539], Loss: 0.803701\nEpoch: 6, [27520/28539], Loss: 0.878589\nEpoch: 6, [27840/28539], Loss: 0.625910\nEpoch: 6, [28160/28539], Loss: 0.965898\nEpoch: 6, [28480/28539], Loss: 0.829886\nEpoch 6 training time: 24.56 minutes\nTraininig... (e=7)\nEpoch: 7, [0/28539], Loss: 0.812624\nEpoch: 7, [320/28539], Loss: 0.698937\nEpoch: 7, [640/28539], Loss: 0.572789\nEpoch: 7, [960/28539], Loss: 1.397575\nEpoch: 7, [1280/28539], Loss: 0.826775\nEpoch: 7, [1600/28539], Loss: 0.570010\nEpoch: 7, [1920/28539], Loss: 1.598071\nEpoch: 7, [2240/28539], Loss: 1.121831\nEpoch: 7, [2560/28539], Loss: 0.795463\nEpoch: 7, [2880/28539], Loss: 0.875347\nEpoch: 7, [3200/28539], Loss: 0.764384\nEpoch: 7, [3520/28539], Loss: 0.680768\nEpoch: 7, [3840/28539], Loss: 0.783314\nEpoch: 7, [4160/28539], Loss: 0.599121\nEpoch: 7, [4480/28539], Loss: 0.674406\nEpoch: 7, [4800/28539], Loss: 0.749798\nEpoch: 7, [5120/28539], Loss: 0.781314\nEpoch: 7, [5440/28539], Loss: 0.786381\nEpoch: 7, [5760/28539], Loss: 0.784123\nEpoch: 7, [6080/28539], Loss: 0.651098\nEpoch: 7, [6400/28539], Loss: 0.900312\nEpoch: 7, [6720/28539], Loss: 0.684968\nEpoch: 7, [7040/28539], Loss: 0.818171\nEpoch: 7, [7360/28539], Loss: 0.673584\nEpoch: 7, [7680/28539], Loss: 0.776721\nEpoch: 7, [8000/28539], Loss: 0.672253\nEpoch: 7, [8320/28539], Loss: 0.749215\nEpoch: 7, [8640/28539], Loss: 0.915503\nEpoch: 7, [8960/28539], Loss: 0.777227\nEpoch: 7, [9280/28539], Loss: 0.756120\nEpoch: 7, [9600/28539], Loss: 1.108096\nEpoch: 7, [9920/28539], Loss: 0.931007\nEpoch: 7, [10240/28539], Loss: 0.773203\nEpoch: 7, [10560/28539], Loss: 1.153531\nEpoch: 7, [10880/28539], Loss: 0.699980\nEpoch: 7, [11200/28539], Loss: 0.848981\nEpoch: 7, [11520/28539], Loss: 0.943324\nEpoch: 7, [11840/28539], Loss: 0.793684\nEpoch: 7, [12160/28539], Loss: 0.680005\nEpoch: 7, [12480/28539], Loss: 0.710782\nEpoch: 7, [12800/28539], Loss: 0.810086\nEpoch: 7, [13120/28539], Loss: 0.803594\nEpoch: 7, [13440/28539], Loss: 0.691642\nEpoch: 7, [13760/28539], Loss: 1.051731\nEpoch: 7, [14080/28539], Loss: 0.637661\nEpoch: 7, [14400/28539], Loss: 0.684267\nEpoch: 7, [14720/28539], Loss: 0.906102\nEpoch: 7, [15040/28539], Loss: 0.891384\nEpoch: 7, [15360/28539], Loss: 0.819813\nEpoch: 7, [15680/28539], Loss: 0.852939\nEpoch: 7, [16000/28539], Loss: 0.546578\nEpoch: 7, [16320/28539], Loss: 1.000702\nEpoch: 7, [16640/28539], Loss: 0.661964\nEpoch: 7, [16960/28539], Loss: 0.630283\nEpoch: 7, [17280/28539], Loss: 0.983415\nEpoch: 7, [17600/28539], Loss: 0.884153\nEpoch: 7, [17920/28539], Loss: 0.729622\nEpoch: 7, [18240/28539], Loss: 0.899434\nEpoch: 7, [18560/28539], Loss: 0.668056\nEpoch: 7, [18880/28539], Loss: 0.687166\nEpoch: 7, [19200/28539], Loss: 0.721338\nEpoch: 7, [19520/28539], Loss: 0.680021\nEpoch: 7, [19840/28539], Loss: 0.773726\nEpoch: 7, [20160/28539], Loss: 0.859915\nEpoch: 7, [20480/28539], Loss: 0.780080\nEpoch: 7, [20800/28539], Loss: 1.034795\nEpoch: 7, [21120/28539], Loss: 1.002323\nEpoch: 7, [21440/28539], Loss: 0.899441\nEpoch: 7, [21760/28539], Loss: 0.671365\nEpoch: 7, [22080/28539], Loss: 0.836908\nEpoch: 7, [22400/28539], Loss: 0.660323\nEpoch: 7, [22720/28539], Loss: 1.081849\nEpoch: 7, [23040/28539], Loss: 1.135693\nEpoch: 7, [23360/28539], Loss: 0.749281\nEpoch: 7, [23680/28539], Loss: 0.895922\nEpoch: 7, [24000/28539], Loss: 0.753642\nEpoch: 7, [24320/28539], Loss: 0.793524\nEpoch: 7, [24640/28539], Loss: 0.620727\nEpoch: 7, [24960/28539], Loss: 0.676470\nEpoch: 7, [25280/28539], Loss: 0.936879\nEpoch: 7, [25600/28539], Loss: 0.646531\nEpoch: 7, [25920/28539], Loss: 0.586058\nEpoch: 7, [26240/28539], Loss: 0.948599\nEpoch: 7, [26560/28539], Loss: 0.626202\nEpoch: 7, [26880/28539], Loss: 0.754837\nEpoch: 7, [27200/28539], Loss: 0.782076\nEpoch: 7, [27520/28539], Loss: 0.775095\nEpoch: 7, [27840/28539], Loss: 0.577176\nEpoch: 7, [28160/28539], Loss: 0.906511\nEpoch: 7, [28480/28539], Loss: 0.741644\nEpoch 7 training time: 24.51 minutes\nTraininig... (e=8)\nEpoch: 8, [0/28539], Loss: 0.720406\nEpoch: 8, [320/28539], Loss: 0.631445\nEpoch: 8, [640/28539], Loss: 0.535905\nEpoch: 8, [960/28539], Loss: 1.370204\nEpoch: 8, [1280/28539], Loss: 0.744745\nEpoch: 8, [1600/28539], Loss: 0.508087\nEpoch: 8, [1920/28539], Loss: 1.608038\nEpoch: 8, [2240/28539], Loss: 0.980440\nEpoch: 8, [2560/28539], Loss: 0.713982\nEpoch: 8, [2880/28539], Loss: 0.840090\nEpoch: 8, [3200/28539], Loss: 0.730150\nEpoch: 8, [3520/28539], Loss: 0.648890\nEpoch: 8, [3840/28539], Loss: 0.717999\nEpoch: 8, [4160/28539], Loss: 0.504014\nEpoch: 8, [4480/28539], Loss: 0.643185\nEpoch: 8, [4800/28539], Loss: 0.723541\nEpoch: 8, [5120/28539], Loss: 0.744621\nEpoch: 8, [5440/28539], Loss: 0.687085\nEpoch: 8, [5760/28539], Loss: 0.663314\nEpoch: 8, [6080/28539], Loss: 0.606079\nEpoch: 8, [6400/28539], Loss: 0.804515\nEpoch: 8, [6720/28539], Loss: 0.624259\nEpoch: 8, [7040/28539], Loss: 0.729861\nEpoch: 8, [7360/28539], Loss: 0.577365\nEpoch: 8, [7680/28539], Loss: 0.732600\nEpoch: 8, [8000/28539], Loss: 0.629158\nEpoch: 8, [8320/28539], Loss: 0.670929\nEpoch: 8, [8640/28539], Loss: 0.821459\nEpoch: 8, [8960/28539], Loss: 0.692310\nEpoch: 8, [9280/28539], Loss: 0.641020\nEpoch: 8, [9600/28539], Loss: 0.979513\nEpoch: 8, [9920/28539], Loss: 0.846529\nEpoch: 8, [10240/28539], Loss: 0.718186\nEpoch: 8, [10560/28539], Loss: 1.115586\nEpoch: 8, [10880/28539], Loss: 0.604210\nEpoch: 8, [11200/28539], Loss: 0.770844\nEpoch: 8, [11520/28539], Loss: 0.866806\nEpoch: 8, [11840/28539], Loss: 0.797113\nEpoch: 8, [12160/28539], Loss: 0.603451\nEpoch: 8, [12480/28539], Loss: 0.633765\nEpoch: 8, [12800/28539], Loss: 0.689566\nEpoch: 8, [13120/28539], Loss: 0.755678\nEpoch: 8, [13440/28539], Loss: 0.594274\nEpoch: 8, [13760/28539], Loss: 0.985924\nEpoch: 8, [14080/28539], Loss: 0.556282\nEpoch: 8, [14400/28539], Loss: 0.610638\nEpoch: 8, [14720/28539], Loss: 0.809644\nEpoch: 8, [15040/28539], Loss: 0.787294\nEpoch: 8, [15360/28539], Loss: 0.766253\nEpoch: 8, [15680/28539], Loss: 0.727549\nEpoch: 8, [16000/28539], Loss: 0.509009\nEpoch: 8, [16320/28539], Loss: 0.912294\nEpoch: 8, [16640/28539], Loss: 0.545120\nEpoch: 8, [16960/28539], Loss: 0.565901\nEpoch: 8, [17280/28539], Loss: 0.868355\nEpoch: 8, [17600/28539], Loss: 0.829607\nEpoch: 8, [17920/28539], Loss: 0.627573\nEpoch: 8, [18240/28539], Loss: 0.752096\nEpoch: 8, [18560/28539], Loss: 0.570650\nEpoch: 8, [18880/28539], Loss: 0.589721\nEpoch: 8, [19200/28539], Loss: 0.615408\nEpoch: 8, [19520/28539], Loss: 0.695391\nEpoch: 8, [19840/28539], Loss: 0.638411\nEpoch: 8, [20160/28539], Loss: 0.773175\nEpoch: 8, [20480/28539], Loss: 0.716577\nEpoch: 8, [20800/28539], Loss: 0.868604\nEpoch: 8, [21120/28539], Loss: 0.931612\nEpoch: 8, [21440/28539], Loss: 0.856448\nEpoch: 8, [21760/28539], Loss: 0.693666\nEpoch: 8, [22080/28539], Loss: 0.794945\nEpoch: 8, [22400/28539], Loss: 0.663599\nEpoch: 8, [22720/28539], Loss: 1.052309\nEpoch: 8, [23040/28539], Loss: 1.009086\nEpoch: 8, [23360/28539], Loss: 0.693818\nEpoch: 8, [23680/28539], Loss: 0.778839\nEpoch: 8, [24000/28539], Loss: 0.713634\nEpoch: 8, [24320/28539], Loss: 0.721744\nEpoch: 8, [24640/28539], Loss: 0.574355\nEpoch: 8, [24960/28539], Loss: 0.634031\nEpoch: 8, [25280/28539], Loss: 0.804955\nEpoch: 8, [25600/28539], Loss: 0.580700\nEpoch: 8, [25920/28539], Loss: 0.526970\nEpoch: 8, [26240/28539], Loss: 0.877376\nEpoch: 8, [26560/28539], Loss: 0.550247\nEpoch: 8, [26880/28539], Loss: 0.624071\nEpoch: 8, [27200/28539], Loss: 0.698153\nEpoch: 8, [27520/28539], Loss: 0.696916\nEpoch: 8, [27840/28539], Loss: 0.528866\nEpoch: 8, [28160/28539], Loss: 0.908137\nEpoch: 8, [28480/28539], Loss: 0.693285\nEpoch 8 training time: 24.68 minutes\nTraininig... (e=9)\nEpoch: 9, [0/28539], Loss: 0.628508\nEpoch: 9, [320/28539], Loss: 0.545912\nEpoch: 9, [640/28539], Loss: 0.517028\nEpoch: 9, [960/28539], Loss: 1.207684\nEpoch: 9, [1280/28539], Loss: 0.664323\nEpoch: 9, [1600/28539], Loss: 0.501125\nEpoch: 9, [1920/28539], Loss: 1.388248\nEpoch: 9, [2240/28539], Loss: 0.863149\nEpoch: 9, [2560/28539], Loss: 0.631779\nEpoch: 9, [2880/28539], Loss: 0.748757\nEpoch: 9, [3200/28539], Loss: 0.655309\nEpoch: 9, [3520/28539], Loss: 0.532204\nEpoch: 9, [3840/28539], Loss: 0.726629\nEpoch: 9, [4160/28539], Loss: 0.475450\nEpoch: 9, [4480/28539], Loss: 0.587238\nEpoch: 9, [4800/28539], Loss: 0.605356\nEpoch: 9, [5120/28539], Loss: 0.662477\nEpoch: 9, [5440/28539], Loss: 0.633320\nEpoch: 9, [5760/28539], Loss: 0.576719\nEpoch: 9, [6080/28539], Loss: 0.514084\nEpoch: 9, [6400/28539], Loss: 0.736991\nEpoch: 9, [6720/28539], Loss: 0.620861\nEpoch: 9, [7040/28539], Loss: 0.799668\nEpoch: 9, [7360/28539], Loss: 0.563462\nEpoch: 9, [7680/28539], Loss: 0.680153\nEpoch: 9, [8000/28539], Loss: 0.586980\nEpoch: 9, [8320/28539], Loss: 0.630544\nEpoch: 9, [8640/28539], Loss: 0.792447\nEpoch: 9, [8960/28539], Loss: 0.631756\nEpoch: 9, [9280/28539], Loss: 0.659328\nEpoch: 9, [9600/28539], Loss: 0.962715\nEpoch: 9, [9920/28539], Loss: 0.794353\nEpoch: 9, [10240/28539], Loss: 0.633333\nEpoch: 9, [10560/28539], Loss: 0.991658\nEpoch: 9, [10880/28539], Loss: 0.606556\nEpoch: 9, [11200/28539], Loss: 0.698403\nEpoch: 9, [11520/28539], Loss: 0.892887\nEpoch: 9, [11840/28539], Loss: 0.692299\nEpoch: 9, [12160/28539], Loss: 0.587575\nEpoch: 9, [12480/28539], Loss: 0.591628\nEpoch: 9, [12800/28539], Loss: 0.655579\nEpoch: 9, [13120/28539], Loss: 0.711412\nEpoch: 9, [13440/28539], Loss: 0.564982\nEpoch: 9, [13760/28539], Loss: 0.906588\nEpoch: 9, [14080/28539], Loss: 0.527350\nEpoch: 9, [14400/28539], Loss: 0.627938\nEpoch: 9, [14720/28539], Loss: 0.647185\nEpoch: 9, [15040/28539], Loss: 0.724529\nEpoch: 9, [15360/28539], Loss: 0.661354\nEpoch: 9, [15680/28539], Loss: 0.658407\nEpoch: 9, [16000/28539], Loss: 0.432999\nEpoch: 9, [16320/28539], Loss: 0.776881\nEpoch: 9, [16640/28539], Loss: 0.522240\nEpoch: 9, [16960/28539], Loss: 0.530302\nEpoch: 9, [17280/28539], Loss: 0.800858\nEpoch: 9, [17600/28539], Loss: 0.731432\nEpoch: 9, [17920/28539], Loss: 0.580912\nEpoch: 9, [18240/28539], Loss: 0.712888\nEpoch: 9, [18560/28539], Loss: 0.526193\nEpoch: 9, [18880/28539], Loss: 0.548713\nEpoch: 9, [19200/28539], Loss: 0.585579\nEpoch: 9, [19520/28539], Loss: 0.599750\nEpoch: 9, [19840/28539], Loss: 0.574067\nEpoch: 9, [20160/28539], Loss: 0.732108\nEpoch: 9, [20480/28539], Loss: 0.633517\nEpoch: 9, [20800/28539], Loss: 0.829869\nEpoch: 9, [21120/28539], Loss: 0.831247\nEpoch: 9, [21440/28539], Loss: 0.794803\nEpoch: 9, [21760/28539], Loss: 0.624051\nEpoch: 9, [22080/28539], Loss: 0.711843\nEpoch: 9, [22400/28539], Loss: 0.617872\nEpoch: 9, [22720/28539], Loss: 0.919528\nEpoch: 9, [23040/28539], Loss: 0.965069\nEpoch: 9, [23360/28539], Loss: 0.611473\nEpoch: 9, [23680/28539], Loss: 0.711243\nEpoch: 9, [24000/28539], Loss: 0.666730\nEpoch: 9, [24320/28539], Loss: 0.676784\nEpoch: 9, [24640/28539], Loss: 0.532290\nEpoch: 9, [24960/28539], Loss: 0.601904\nEpoch: 9, [25280/28539], Loss: 0.684777\nEpoch: 9, [25600/28539], Loss: 0.545896\nEpoch: 9, [25920/28539], Loss: 0.523764\nEpoch: 9, [26240/28539], Loss: 0.827730\nEpoch: 9, [26560/28539], Loss: 0.454377\nEpoch: 9, [26880/28539], Loss: 0.565296\nEpoch: 9, [27200/28539], Loss: 0.556322\nEpoch: 9, [27520/28539], Loss: 0.676808\nEpoch: 9, [27840/28539], Loss: 0.489465\nEpoch: 9, [28160/28539], Loss: 0.769429\nEpoch: 9, [28480/28539], Loss: 0.613460\nEpoch 9 training time: 24.51 minutes\nTraininig... (e=10)\nEpoch: 10, [0/28539], Loss: 0.610532\nEpoch: 10, [320/28539], Loss: 0.491461\nEpoch: 10, [640/28539], Loss: 0.422354\nEpoch: 10, [960/28539], Loss: 1.193045\nEpoch: 10, [1280/28539], Loss: 0.597139\nEpoch: 10, [1600/28539], Loss: 0.460465\nEpoch: 10, [1920/28539], Loss: 1.362015\nEpoch: 10, [2240/28539], Loss: 0.844050\nEpoch: 10, [2560/28539], Loss: 0.660243\nEpoch: 10, [2880/28539], Loss: 0.730926\nEpoch: 10, [3200/28539], Loss: 0.620820\nEpoch: 10, [3520/28539], Loss: 0.602188\nEpoch: 10, [3840/28539], Loss: 0.632504\nEpoch: 10, [4160/28539], Loss: 0.423591\nEpoch: 10, [4480/28539], Loss: 0.519693\nEpoch: 10, [4800/28539], Loss: 0.597683\nEpoch: 10, [5120/28539], Loss: 0.636047\nEpoch: 10, [5440/28539], Loss: 0.584471\nEpoch: 10, [5760/28539], Loss: 0.560821\nEpoch: 10, [6080/28539], Loss: 0.494739\nEpoch: 10, [6400/28539], Loss: 0.655508\nEpoch: 10, [6720/28539], Loss: 0.569117\nEpoch: 10, [7040/28539], Loss: 0.612642\nEpoch: 10, [7360/28539], Loss: 0.506066\nEpoch: 10, [7680/28539], Loss: 0.642527\nEpoch: 10, [8000/28539], Loss: 0.521245\nEpoch: 10, [8320/28539], Loss: 0.556355\nEpoch: 10, [8640/28539], Loss: 0.640458\nEpoch: 10, [8960/28539], Loss: 0.575055\nEpoch: 10, [9280/28539], Loss: 0.629427\nEpoch: 10, [9600/28539], Loss: 0.904641\nEpoch: 10, [9920/28539], Loss: 0.720230\nEpoch: 10, [10240/28539], Loss: 0.618700\nEpoch: 10, [10560/28539], Loss: 1.006029\nEpoch: 10, [10880/28539], Loss: 0.512060\nEpoch: 10, [11200/28539], Loss: 0.643827\nEpoch: 10, [11520/28539], Loss: 0.778321\nEpoch: 10, [11840/28539], Loss: 0.644250\nEpoch: 10, [12160/28539], Loss: 0.463071\nEpoch: 10, [12480/28539], Loss: 0.558864\nEpoch: 10, [12800/28539], Loss: 0.609140\nEpoch: 10, [13120/28539], Loss: 0.669010\nEpoch: 10, [13440/28539], Loss: 0.490732\nEpoch: 10, [13760/28539], Loss: 0.859059\nEpoch: 10, [14080/28539], Loss: 0.442284\nEpoch: 10, [14400/28539], Loss: 0.568052\nEpoch: 10, [14720/28539], Loss: 0.583813\nEpoch: 10, [15040/28539], Loss: 0.687760\nEpoch: 10, [15360/28539], Loss: 0.603279\nEpoch: 10, [15680/28539], Loss: 0.697887\nEpoch: 10, [16000/28539], Loss: 0.413520\nEpoch: 10, [16320/28539], Loss: 0.830319\nEpoch: 10, [16640/28539], Loss: 0.523109\nEpoch: 10, [16960/28539], Loss: 0.505602\nEpoch: 10, [17280/28539], Loss: 0.772450\nEpoch: 10, [17600/28539], Loss: 0.628463\nEpoch: 10, [17920/28539], Loss: 0.544588\nEpoch: 10, [18240/28539], Loss: 0.609142\nEpoch: 10, [18560/28539], Loss: 0.462761\nEpoch: 10, [18880/28539], Loss: 0.483087\nEpoch: 10, [19200/28539], Loss: 0.511075\nEpoch: 10, [19520/28539], Loss: 0.569686\nEpoch: 10, [19840/28539], Loss: 0.599089\nEpoch: 10, [20160/28539], Loss: 0.690817\nEpoch: 10, [20480/28539], Loss: 0.595927\nEpoch: 10, [20800/28539], Loss: 0.768342\nEpoch: 10, [21120/28539], Loss: 0.793275\nEpoch: 10, [21440/28539], Loss: 0.711380\nEpoch: 10, [21760/28539], Loss: 0.570574\nEpoch: 10, [22080/28539], Loss: 0.705660\nEpoch: 10, [22400/28539], Loss: 0.550332\nEpoch: 10, [22720/28539], Loss: 0.862836\nEpoch: 10, [23040/28539], Loss: 0.929393\nEpoch: 10, [23360/28539], Loss: 0.590954\nEpoch: 10, [23680/28539], Loss: 0.731553\nEpoch: 10, [24000/28539], Loss: 0.583747\nEpoch: 10, [24320/28539], Loss: 0.600104\nEpoch: 10, [24640/28539], Loss: 0.479687\nEpoch: 10, [24960/28539], Loss: 0.571576\nEpoch: 10, [25280/28539], Loss: 0.697209\nEpoch: 10, [25600/28539], Loss: 0.514288\nEpoch: 10, [25920/28539], Loss: 0.448400\nEpoch: 10, [26240/28539], Loss: 0.682370\nEpoch: 10, [26560/28539], Loss: 0.447778\nEpoch: 10, [26880/28539], Loss: 0.491850\nEpoch: 10, [27200/28539], Loss: 0.566201\nEpoch: 10, [27520/28539], Loss: 0.709986\nEpoch: 10, [27840/28539], Loss: 0.462491\nEpoch: 10, [28160/28539], Loss: 0.733568\nEpoch: 10, [28480/28539], Loss: 0.643401\nEpoch 10 training time: 24.62 minutes\n\nTotal training time: 250.59 minutes\n\nAverage training time: 25.06 minutes\nTesting on test-clean (epoch=10)\nLoss: 0.574618\nWER: 0.4812\nCER: 0.1705\nTest Loss: 0.5746\nTest WER: 0.4812\nTest CER: 0.1705\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot(range(1, epochs + 1), train_loss, label='Training Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.title('Loss curve for Training dataset')\nplt.legend()\nplt.grid(True)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T19:01:33.703636Z","iopub.execute_input":"2025-04-08T19:01:33.703955Z","iopub.status.idle":"2025-04-08T19:01:33.979480Z","shell.execute_reply.started":"2025-04-08T19:01:33.703922Z","shell.execute_reply":"2025-04-08T19:01:33.978722Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"torch.save(model_to_train.state_dict(), 'model_weights.pth')\n\ntorch.save({\n    'epoch': epoch,\n    'model_state_dict': model_to_train.state_dict(),\n    'optimizer_state_dict': adamW.state_dict(),\n    'loss': train_loss[-1],\n    'test_loss': test_epoch_loss,\n    'test_wer': test_epoch_wer,\n    'test_cer': test_epoch_cer\n}, 'model_results.pth')\n\nprint(\"\\nModel saved successfully.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T19:01:33.981711Z","iopub.execute_input":"2025-04-08T19:01:33.981922Z","iopub.status.idle":"2025-04-08T19:01:34.457033Z","shell.execute_reply.started":"2025-04-08T19:01:33.981903Z","shell.execute_reply":"2025-04-08T19:01:34.456124Z"}},"outputs":[{"name":"stdout","text":"\nModel saved successfully.\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}