{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10985935,"sourceType":"datasetVersion","datasetId":6837553}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip3 install Levenshtein","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-17T03:48:44.233527Z","iopub.execute_input":"2025-04-17T03:48:44.233763Z","iopub.status.idle":"2025-04-17T03:48:49.983917Z","shell.execute_reply.started":"2025-04-17T03:48:44.233738Z","shell.execute_reply":"2025-04-17T03:48:49.983207Z"}},"outputs":[{"name":"stdout","text":"Collecting Levenshtein\n  Downloading levenshtein-0.27.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\nCollecting rapidfuzz<4.0.0,>=3.9.0 (from Levenshtein)\n  Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\nDownloading levenshtein-0.27.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (161 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.7/161.7 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: rapidfuzz, Levenshtein\nSuccessfully installed Levenshtein-0.27.1 rapidfuzz-3.13.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader\nimport torch\nimport torch.nn as nn\nimport torchaudio\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport numpy as np\nimport Levenshtein\nimport math","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T03:48:49.985340Z","iopub.execute_input":"2025-04-17T03:48:49.985600Z","iopub.status.idle":"2025-04-17T03:48:54.429348Z","shell.execute_reply.started":"2025-04-17T03:48:49.985580Z","shell.execute_reply":"2025-04-17T03:48:54.428757Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"!ls /kaggle/input/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T03:48:54.430021Z","iopub.execute_input":"2025-04-17T03:48:54.430394Z","iopub.status.idle":"2025-04-17T03:48:54.560047Z","shell.execute_reply.started":"2025-04-17T03:48:54.430370Z","shell.execute_reply":"2025-04-17T03:48:54.559410Z"}},"outputs":[{"name":"stdout","text":"librispeech-datasets\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T03:48:54.561052Z","iopub.execute_input":"2025-04-17T03:48:54.561344Z","iopub.status.idle":"2025-04-17T03:48:54.627998Z","shell.execute_reply.started":"2025-04-17T03:48:54.561315Z","shell.execute_reply":"2025-04-17T03:48:54.627253Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"\ndataset_path = \"/kaggle/input/librispeech-datasets/\"\ndef download(dataset):\n    audioset = torchaudio.datasets.LIBRISPEECH(dataset_path+'/'+dataset,url=dataset,download=False)\n    return audioset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T03:48:54.630109Z","iopub.execute_input":"2025-04-17T03:48:54.630334Z","iopub.status.idle":"2025-04-17T03:48:54.641929Z","shell.execute_reply.started":"2025-04-17T03:48:54.630317Z","shell.execute_reply":"2025-04-17T03:48:54.641320Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"train_clean = download('train-clean-100')\ndev_clean = download('dev-clean')\ntest_clean = download('test-clean')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T03:48:54.642496Z","iopub.execute_input":"2025-04-17T03:48:54.642723Z","iopub.status.idle":"2025-04-17T03:48:59.973820Z","shell.execute_reply.started":"2025-04-17T03:48:54.642668Z","shell.execute_reply":"2025-04-17T03:48:59.973250Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"class Unigram():\n    def __init__(self,word_model_type):\n        self.word_model_type = 'unigram'\n        self.blank_id = 28\n        self.n_class = 29\n\n        self.SPACE = \"[space]\"\n        self.characters = \"' \" + self.SPACE + \" \" +\" \".join(\"abcdefghijklmnopqrstuvwxyz\")\n        self.tokens = self.characters.split(' ')\n\n        self.char_to_id = {char: idx for idx, char in enumerate(self.tokens)}\n        self.id_to_char = {idx: char for idx, char in enumerate(self.tokens)}\n\n    def text_to_int(self, sentence: str):\n        idx_sequence = []\n        for ch in sentence:\n            idx = self.char_to_id[self.SPACE] if ch == \" \" else self.char_to_id[ch]\n            idx_sequence.append(idx)\n        return idx_sequence\n\n    def int_to_text(self, indices):\n        sentence = []\n        for i in indices:\n            ch = self.id_to_char[i]\n            sentence.append(ch)\n        return \"\".join(sentence).replace(self.SPACE, \" \")\n\n\nword_encoding_model = Unigram('unigram')\noriginal = \"my name is olan\"\nencoded = word_encoding_model.text_to_int(original)\nreconstructed = word_encoding_model.int_to_text(encoded)\nprint(original)\nprint(encoded)\nprint(reconstructed)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T03:48:59.974613Z","iopub.execute_input":"2025-04-17T03:48:59.974830Z","iopub.status.idle":"2025-04-17T03:48:59.982055Z","shell.execute_reply.started":"2025-04-17T03:48:59.974814Z","shell.execute_reply":"2025-04-17T03:48:59.981267Z"}},"outputs":[{"name":"stdout","text":"my name is olan\n[14, 26, 1, 15, 2, 14, 6, 1, 10, 20, 1, 16, 13, 2, 15]\nmy name is olan\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"def preprocess(audioset,split,stride,word_model):\n\n        if split[:5] == \"train\":\n            train_pipe = nn.Sequential(\n                torchaudio.transforms.MelSpectrogram(sample_rate=16000, n_mels=128),\n                torchaudio.transforms.FrequencyMasking(freq_mask_param=15),\n                torchaudio.transforms.TimeMasking(time_mask_param=35))\n            augment_fn = train_pipe\n        else:\n            test_pipe = torchaudio.transforms.MelSpectrogram()\n            augment_fn = test_pipe\n      \n        spectrograms = []\n        indices = []\n        len_spectrograms = []\n        len_indices = []\n        \n        for waveform, _, transcript, _, _, _ in audioset:\n            # Augment audio data\n            spec = augment_fn(waveform).squeeze(0).transpose(0,1)\n            spectrograms.append(spec)\n\n            # Convert text transcript to sequence of ids\n            ids = torch.Tensor(word_model.text_to_int(transcript.lower()))\n            indices.append(ids)\n\n            # Append audio and text length\n            if stride == 2:\n                len_spec = spec.shape[0]//stride\n            else:\n                len_spec = spec.shape[0]//stride - 2\n            \n            len_spectrograms.append(len_spec)\n            len_indices.append(len(ids))\n        \n        # Zero pad\n        spectrograms = nn.utils.rnn.pad_sequence(spectrograms, batch_first=True).unsqueeze(1).transpose(2, 3)\n        indices = nn.utils.rnn.pad_sequence(indices, batch_first=True)\n\n        return spectrograms, indices, len_spectrograms, len_indices","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T03:48:59.982794Z","iopub.execute_input":"2025-04-17T03:48:59.983061Z","iopub.status.idle":"2025-04-17T03:48:59.999623Z","shell.execute_reply.started":"2025-04-17T03:48:59.983036Z","shell.execute_reply":"2025-04-17T03:48:59.998964Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def reading_data_sample(loader):\n    print(\"Data length : \",len(loader.dataset))\n    for batch_sample in loader:\n        print(\"Spectrogram shape:\", list(batch_sample[0].shape))\n        print(\"Label shape:\", list(batch_sample[1].shape))\n        print(\"Mel length (length of each spectrogram):\", batch_sample[2][:6], \"...\")\n        print(\"Idx length (length of each label):\", batch_sample[3][:6], \"...\")\n        break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T03:49:00.000302Z","iopub.execute_input":"2025-04-17T03:49:00.000498Z","iopub.status.idle":"2025-04-17T03:49:00.017932Z","shell.execute_reply.started":"2025-04-17T03:49:00.000483Z","shell.execute_reply":"2025-04-17T03:49:00.017326Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# General Hyper-params\nbatch_size = 8\nepochs =10\n\nn_features = 128 \nstride = 2      \n\nlr = 0.0005","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T03:49:00.018611Z","iopub.execute_input":"2025-04-17T03:49:00.019081Z","iopub.status.idle":"2025-04-17T03:49:00.033439Z","shell.execute_reply.started":"2025-04-17T03:49:00.019065Z","shell.execute_reply":"2025-04-17T03:49:00.032926Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"train_loader  = DataLoader(dataset=train_clean,\n                               batch_size=batch_size,\n                               shuffle=False,\n                               collate_fn=lambda x: preprocess(x, \"train-clean-100\", stride, word_encoding_model))\n\n\ndev_clean_loader = DataLoader(dataset=dev_clean,\n                               batch_size=batch_size,\n                               shuffle=False,\n                               collate_fn=lambda x: preprocess(x, \"dev-clean\", stride, word_encoding_model))\n\n\ntest_clean_loader = DataLoader(dataset=test_clean,\n                               batch_size=batch_size,\n                               shuffle=False,\n                               collate_fn=lambda x: preprocess(x, \"test-clean\", stride, word_encoding_model))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T03:49:00.034233Z","iopub.execute_input":"2025-04-17T03:49:00.034424Z","iopub.status.idle":"2025-04-17T03:49:00.056484Z","shell.execute_reply.started":"2025-04-17T03:49:00.034410Z","shell.execute_reply":"2025-04-17T03:49:00.055855Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"print(f\"Train : {len(train_loader.dataset)} samples \")\nprint(f\"Dev Clean : {len(dev_clean_loader.dataset)} samples \")\nprint(f\"Test Clean : {len(test_clean_loader.dataset)} samples \")\nprint()\n\nreading_data_sample(train_loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T03:49:00.057277Z","iopub.execute_input":"2025-04-17T03:49:00.057715Z","iopub.status.idle":"2025-04-17T03:49:00.446827Z","shell.execute_reply.started":"2025-04-17T03:49:00.057693Z","shell.execute_reply":"2025-04-17T03:49:00.446020Z"}},"outputs":[{"name":"stdout","text":"Train : 28539 samples \nDev Clean : 2703 samples \nTest Clean : 2620 samples \n\nData length :  28539\nSpectrogram shape: [8, 1, 128, 1276]\nLabel shape: [8, 283]\nMel length (length of each spectrogram): [563, 638, 558, 588, 501, 607] ...\nIdx length (length of each label): [201, 283, 250, 268, 227, 263] ...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"class ConformerMHSA(nn.Module):\n    def __init__(self, num_features, device, num_heads, max_rel_pos=800, drop_rate=0.1):\n\n        super(ConformerMHSA, self).__init__()\n\n        self.emb_dim = num_features\n        self.num_heads = num_heads\n        self.max_rel_pos = max_rel_pos\n\n        self.norm = nn.LayerNorm(num_features)\n        self.attention = nn.MultiheadAttention(num_features, num_heads, batch_first=True)\n        self.dropout = nn.Dropout(p=drop_rate)\n        \n        self.device = device\n        self.pos_matrix = self.get_positional_matrix().to(self.device)\n\n\n    def get_positional_matrix(self):\n        \"\"\"\n        Create positional matrix of shape (2*self.max_rel_pos + 1, emb_dim)\n        Only (:seq_len, emb_dim) will be summed to input tensors\n        \"\"\"\n        matrix = torch.zeros(2*self.max_rel_pos + 1, self.emb_dim)\n\n        pos = torch.arange(0, 2*self.max_rel_pos + 1).unsqueeze(1).float()\n        divisor = torch.exp(torch.arange(0, self.emb_dim, 2).float() * -math.log(10000) / self.emb_dim)\n        \n        matrix[:, 0::2] = torch.sin(pos*divisor)\n        matrix[:, 1::2] = torch.cos(pos*divisor)\n        final_matrix = matrix.unsqueeze(0)\n\n        return final_matrix\n\n    def forward(self, x):\n        # Input shape: [batch, seq_len, num_features]\n        batch_size, seq_len, _ = x.size()\n\n        skip = x\n\n        x = self.norm(x)\n        pos_emb = self.pos_matrix[:, :seq_len, :].expand(batch_size, seq_len, self.emb_dim)\n        x += pos_emb\n        x, _ = self.attention(x, x, x)\n        x = self.dropout(x)\n\n        x += skip\n\n        return x\n\nclass ConformerConv(nn.Module):\n    def __init__(self, num_features, kernel_size, exp_factor=2, drop_rate=0.1):\n\n        super(ConformerConv, self).__init__()\n\n        self.layer_norm = nn.LayerNorm(num_features)\n        self.point_conv_1 = nn.Conv1d(in_channels=num_features,\n                                      out_channels=num_features*exp_factor,\n                                      kernel_size=1)\n        self.glu = nn.GLU(dim=1)\n        self.depth_conv = nn.Conv1d(in_channels=num_features,\n                                    out_channels=num_features,\n                                    kernel_size=kernel_size,\n                                    padding=(kernel_size-1)//2,\n                                    groups=num_features)\n        \n        self.batch_norm = nn.BatchNorm1d(num_features)\n        self.swish = nn.SiLU()\n        self.point_conv_2 = nn.Conv1d(in_channels=num_features,\n                                      out_channels=num_features,\n                                      kernel_size=1)\n        self.dropout = nn.Dropout(p=drop_rate)\n\n    def forward(self, x):\n\n        skip = x # [batch_size, seq_len, num_features] \n        x = self.layer_norm(x)\n\n        x = x.transpose(1, 2).contiguous() # [batch_size, num_features, seq_len] \n\n        x = self.point_conv_1(x)\n        x = self.glu(x)\n        x = self.depth_conv(x)\n        x = self.batch_norm(x)\n        x = self.swish(x)\n        x = self.point_conv_2(x)\n        x = self.dropout(x)\n\n        x = x.transpose(1, 2).contiguous() # [batch_size, seq_len, num_features]\n        x += skip\n\n        return x\n\nclass ConformerFFN(nn.Module):\n\n    def __init__(self, num_features, exp_factor=4, drop_rate=0.1):\n\n        super(ConformerFFN, self).__init__()\n\n        self.norm = nn.LayerNorm(num_features)\n\n        self.linear_1 = nn.Linear(num_features, num_features*exp_factor)\n        self.swish = nn.SiLU()\n        self.dropout_1 = nn.Dropout(p=drop_rate)\n\n        self.linear_2 = nn.Linear(num_features*exp_factor, num_features)\n        self.dropout_2 = nn.Dropout(p=drop_rate)\n    \n    def forward(self, x):\n        \n        skip = x # [batch_size, seq_len, num_features]\n\n        x = self.norm(x)\n        \n        x = self.linear_1(x) # [batch_size, seq_len, num_features * exp_factor]\n        x = self.swish(x)\n        x = self.dropout_1(x)\n\n        x = self.linear_2(x) # [batch_size, seq_len, num_features]\n        x = self.dropout_2(x)\n\n        x = skip + 1/2 * x\n\n        return x\n\nclass PostProcess(nn.Module):\n\n    def __init__(self, encoder_dim, hidden_size, n_class):\n\n        super(PostProcess, self).__init__()\n\n        self.lstm = nn.LSTM(input_size=encoder_dim,\n                            hidden_size=hidden_size,\n                            num_layers=1,\n                            batch_first=True)\n        self.scoring = nn.Linear(in_features=hidden_size, out_features=n_class)\n        \n    def forward(self, x):\n        x, _ = self.lstm(x)\n        x = self.scoring(x)\n        return x\n\n\nclass ConvSubsampling(nn.Module):\n\n    def __init__(self, out_channels):\n        \n        super(ConvSubsampling, self).__init__()\n    \n        self.sub_stack = nn.Sequential(\n            nn.Conv2d(in_channels=1,\n                      out_channels=out_channels,\n                      kernel_size=3, stride=2, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(in_channels=out_channels,\n                      out_channels=out_channels,\n                      kernel_size=3, stride=1, padding='same'),\n            nn.ReLU()\n        )\n    \n    def forward(self, x):\n        x = self.sub_stack(x)\n\n        batch_size, channels, seq_len, num_features = x.size()\n        x = x.permute(0, 2, 1, 3).contiguous()\n        x = x.view(batch_size, seq_len, channels*num_features)\n\n        return x\n\nclass PreProcess(nn.Module):\n    def __init__(self, in_features, encoder_dim, drop_rate=0.1):\n\n        super(PreProcess, self).__init__()\n\n        self.out_features = self.get_out_features(in_features)\n\n        self.conv_sub = ConvSubsampling(out_channels=in_features)\n        self.linear = nn.Linear(in_features=self.out_features, out_features=encoder_dim)\n        self.dropout = nn.Dropout(p=drop_rate)\n    \n    def get_out_features(self, in_features):\n        ans = in_features * in_features // 2\n        return ans\n\n    def forward(self, x):\n        x = self.conv_sub(x)\n        x = self.linear(x)\n        x = self.dropout(x)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T03:49:00.447633Z","iopub.execute_input":"2025-04-17T03:49:00.447893Z","iopub.status.idle":"2025-04-17T03:49:00.466818Z","shell.execute_reply.started":"2025-04-17T03:49:00.447871Z","shell.execute_reply":"2025-04-17T03:49:00.466201Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"class ConformerBlock(nn.Module):\n    def __init__(self, encoder_dim, num_heads, kernel_size, device):\n        super(ConformerBlock, self).__init__()\n        self.feed_forward_1 = ConformerFFN(num_features=encoder_dim)\n        self.attention = ConformerMHSA(num_features=encoder_dim, device=device, num_heads=num_heads)\n        self.convolution = ConformerConv(num_features=encoder_dim, kernel_size=kernel_size)\n        self.feed_forward_2 = ConformerFFN(num_features=encoder_dim)\n        self.norm = nn.LayerNorm(normalized_shape=encoder_dim)\n    \n    def forward(self, x):\n        x = self.feed_forward_1(x)\n        x = self.attention(x)\n        x = self.convolution(x)\n        x = self.feed_forward_2(x)\n        x = self.norm(x)\n\n        return x\n\nclass Conformer(nn.Module):\n    def __init__(self,\n                 in_features,\n                 encoder_dim,\n                 num_heads,\n                 kernel_size,\n                 hidden_size,\n                 n_class,\n                 n_blocks,\n                 device):\n\n        super(Conformer, self).__init__()\n\n        self.pre_process = PreProcess(in_features=in_features, encoder_dim=encoder_dim)\n        self.conformer_stack = nn.Sequential(\n            *[ConformerBlock(encoder_dim=encoder_dim,\n                             num_heads=num_heads,\n                             kernel_size=kernel_size,\n                             device=device)\n              for _ in range(n_blocks)])\n        self.post_process = PostProcess(encoder_dim=encoder_dim, hidden_size=hidden_size, n_class=n_class)\n\n    def forward(self, x):\n        \"\"\"\n        Input:  [batch_size, 1, seq_len, num_features]\n        Output: [batch_size, seq_len, n_classes]\n        \"\"\"\n        x = x.transpose(2, 3).contiguous()\n\n        x = self.pre_process(x)\n        x = self.conformer_stack(x)\n        x = self.post_process(x)\n\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T03:49:00.468736Z","iopub.execute_input":"2025-04-17T03:49:00.468931Z","iopub.status.idle":"2025-04-17T03:49:00.487899Z","shell.execute_reply.started":"2025-04-17T03:49:00.468916Z","shell.execute_reply":"2025-04-17T03:49:00.487207Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"cm3 = Conformer(in_features=128,\n                      encoder_dim=256,\n                      num_heads=4,\n                      kernel_size=31,\n                      hidden_size=320,\n                      n_class=29,\n                      n_blocks=16,\n                      device=device).to(device)\n\ntot_params = sum([p.numel() for p in cm3.parameters()])\nprint(f\"Number of parameters: {tot_params}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T03:49:00.488559Z","iopub.execute_input":"2025-04-17T03:49:00.488737Z","iopub.status.idle":"2025-04-17T03:49:01.107878Z","shell.execute_reply.started":"2025-04-17T03:49:00.488723Z","shell.execute_reply":"2025-04-17T03:49:01.107226Z"}},"outputs":[{"name":"stdout","text":"Number of parameters: 27362525\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"model_to_train = cm3\nadamW = optim.AdamW(model_to_train.parameters(), lr)\nctc_loss = nn.CTCLoss(blank=word_encoding_model.blank_id).to(device)\none_cycle_lr = optim.lr_scheduler.OneCycleLR(adamW,\n                                             max_lr=lr,\n                                             steps_per_epoch=int(len(train_loader)),\n                                             epochs=epochs,\n                                             anneal_strategy=\"linear\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T03:49:09.787500Z","iopub.execute_input":"2025-04-17T03:49:09.788198Z","iopub.status.idle":"2025-04-17T03:49:11.954777Z","shell.execute_reply.started":"2025-04-17T03:49:09.788155Z","shell.execute_reply":"2025-04-17T03:49:11.954213Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"def train(epoch, dataset_loader, model, optimizer, scheduler, fn_loss):\n    print(f\"Traininig... (e={epoch})\")\n    \n    # Train mode ON\n    model.train()\n    total_train_loss = 0  #tracking loss\n    n_samples = int(len(dataset_loader.dataset))\n\n    for idx, audio_data in enumerate(dataset_loader):\n        \n        # Get audio data with shape [batch, 1, n_features, seq_len]\n        spectrograms, indices, len_spectrograms, len_indices = audio_data\n        spectrograms, indices = spectrograms.to(device), indices.to(device)\n\n        optimizer.zero_grad()\n\n        # Forward pass\n        out = model(spectrograms)\n        out = F.log_softmax(out, dim=2)\n        out = out.transpose(0, 1)\n        \n        # Backward pass\n        loss = fn_loss(out, indices, len_spectrograms, len_indices)\n        loss.backward()\n\n        # Step\n        optimizer.step()\n        scheduler.step()\n\n        total_train_loss += loss.item()\n        \n\n        # Log\n        if idx % 20 == 0 or idx == n_samples:\n            print(\"Epoch: {}, [{}/{}], Loss: {:.6f}\".format(\n                epoch, \n                idx*len(spectrograms), \n                n_samples,\n                loss.item()))\n\n    avg_train_loss = total_train_loss/n_samples\n    return avg_train_loss\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T03:49:13.497551Z","iopub.execute_input":"2025-04-17T03:49:13.498252Z","iopub.status.idle":"2025-04-17T03:49:13.503925Z","shell.execute_reply.started":"2025-04-17T03:49:13.498228Z","shell.execute_reply":"2025-04-17T03:49:13.503305Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# Computes Word Error Rate\ndef compute_wer(hypothesis, reference):\n    hypothesis_words = hypothesis.split()\n    reference_words = reference.split()\n    \n    wer = Levenshtein.distance(hypothesis_words, reference_words) / len(reference_words)\n    return wer\n\n# Computes Character Error Rate\ndef compute_cer(hypothesis, reference):\n\n    cer = Levenshtein.distance(hypothesis, reference) / len(reference)\n    return cer\n\n#     Calculates CER for each hyp-ref pair, and returns the average\ndef avg_cer(batch_hyp, batch_ref):\n    batch_size = len(batch_ref)\n    out = []\n    for i in range(batch_size):\n        out.append(compute_cer(batch_hyp[i], batch_ref[i]))\n    \n    return sum(out) / batch_size\n\n#     Calculates WER for each hyp-ref pair, and returns the average\ndef avg_wer(batch_hyp, batch_ref):\n    batch_size = len(batch_ref)\n    out = []\n    for i in range(batch_size):\n        out.append(compute_wer(batch_hyp[i], batch_ref[i]))\n    \n    return sum(out) / batch_size","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T03:49:13.934439Z","iopub.execute_input":"2025-04-17T03:49:13.935303Z","iopub.status.idle":"2025-04-17T03:49:13.942033Z","shell.execute_reply.started":"2025-04-17T03:49:13.935270Z","shell.execute_reply":"2025-04-17T03:49:13.941186Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"def decode_prob(prob, word_encoding_model):\n    \"\"\"\n    Decodes (a batch of) log-probabilities\n    into characters.\n    prob -> shape (e.g.) [16, 650, 29]\n    \"\"\"\n    prob = torch.transpose(prob, 0, 1)\n    arg_maxes = torch.argmax(prob, dim=-1) # [16, 650]\n    decodes = []\n\n    for i, args in enumerate(arg_maxes):\n        decode = []\n        for j, index in enumerate(args):\n             # ignore blank id\n            if index == word_encoding_model.blank_id:\n                continue\n            # avoid repetitions\n            if j != 0 and index == args[j-1]:\n                continue\n            decode.append(index.item())\n        decodes.append(word_encoding_model.int_to_text(decode))\n    return decodes\n\n\ndef decode_labels(indices, len_indices, word_encoding_model):\n    \"\"\"\n    Decodes (a batch of) ids into characters.\n    indices -> shape: [32, 300]\n    len_indices -> shape: [32]\n    word_model -> tool to convert idx into chars\n    \"\"\"\n    out = []\n    for i, ids in enumerate(indices):\n        len_ids = len_indices[i]\n        unpad_ids = ids[:len_ids]\n        out.append(word_encoding_model.int_to_text(unpad_ids.tolist()))\n    return out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T03:49:16.082734Z","iopub.execute_input":"2025-04-17T03:49:16.083427Z","iopub.status.idle":"2025-04-17T03:49:16.088768Z","shell.execute_reply.started":"2025-04-17T03:49:16.083403Z","shell.execute_reply":"2025-04-17T03:49:16.088008Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"def test(epoch, dataset_name, dataset_loader, model, optimizer, fn_loss, debug=False):\n    print(f\"Testing on {dataset_name} (epoch={epoch})\")\n    model.eval()\n\n    total_loss = 0\n    wer_list = []\n    cer_list = []\n\n    n_batch = int(len(dataset_loader))\n\n    with torch.no_grad():\n        for idx, audio_data in enumerate(dataset_loader):\n        \n            # Get audio data\n            spectrograms, indices, len_spectrograms, len_indices = audio_data\n            spectrograms, indices = spectrograms.to(device), indices.to(device)\n\n            optimizer.zero_grad()\n            \n            # Forward pass\n            out = model(spectrograms)\n            out = F.log_softmax(out, dim=2)\n            out = out.transpose(0, 1)\n\n            # Compute loss\n            loss = fn_loss(out, indices, len_spectrograms, len_indices)\n            total_loss += loss.item() / n_batch\n\n            # Metrics\n            decode_hypothesis = decode_prob(out, word_encoding_model)\n            decode_reference = decode_labels(indices, len_indices, word_encoding_model)\n\n            wer_list.append(avg_wer(decode_hypothesis, decode_reference))\n            cer_list.append(avg_cer(decode_hypothesis, decode_reference))\n            \n            \n    print(f\"Loss: {total_loss:.6f}\")\n    print(f\"WER: {sum(wer_list)/len(wer_list):.4f}\")\n    print(f\"CER: {sum(cer_list)/len(cer_list):.4f}\")\n\n    avg_test_wer = sum(wer_list) / len(wer_list)\n    avg_test_cer = sum(cer_list) / len(cer_list)\n\n    return total_loss, avg_test_wer, avg_test_cer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T03:49:18.028360Z","iopub.execute_input":"2025-04-17T03:49:18.029037Z","iopub.status.idle":"2025-04-17T03:49:18.035256Z","shell.execute_reply.started":"2025-04-17T03:49:18.029012Z","shell.execute_reply":"2025-04-17T03:49:18.034599Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"import time\n\ntrain_loss = []\ndev_loss = []\ndev_wer = []\ndev_cer = []\ntotal_train_time=0\nfor epoch in range(1, epochs+1):\n    #calculate train time\n    training_start = time.time()\n    \n    train_epoch_loss = train(epoch, train_loader, model_to_train, adamW, one_cycle_lr, ctc_loss)\n\n    training_end = time.time()\n\n    training_time = (training_end - training_start)/60\n    total_train_time+=training_time\n    print(f\"Epoch {epoch} training time: {training_time:.2f} minutes\")\n\n    train_loss.append(train_epoch_loss)\n\n    #dev\n    dev_epoch_loss, dev_epoch_wer, dev_epoch_cer = test(epoch, \"dev-clean\", dev_clean_loader, model_to_train, adamW, ctc_loss)\n    dev_loss.append(dev_epoch_loss)\n    dev_wer.append(dev_epoch_wer)\n    dev_cer.append(dev_epoch_cer)\nprint(\"Total training time : \",total_train_time,\" minutes\")\nprint(\"Average time taken per epoch : \",total_train_time/epochs,\" minutes\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T03:49:20.089957Z","iopub.execute_input":"2025-04-17T03:49:20.090239Z"}},"outputs":[{"name":"stdout","text":"Traininig... (e=1)\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 1, [0/28539], Loss: 5.770763\nEpoch: 1, [160/28539], Loss: 4.938419\nEpoch: 1, [320/28539], Loss: 3.548324\nEpoch: 1, [480/28539], Loss: 3.191332\nEpoch: 1, [640/28539], Loss: 3.118243\nEpoch: 1, [800/28539], Loss: 2.987504\nEpoch: 1, [960/28539], Loss: 3.000678\nEpoch: 1, [1120/28539], Loss: 2.957337\nEpoch: 1, [1280/28539], Loss: 2.912342\nEpoch: 1, [1440/28539], Loss: 2.912927\nEpoch: 1, [1600/28539], Loss: 2.861511\nEpoch: 1, [1760/28539], Loss: 3.064484\nEpoch: 1, [1920/28539], Loss: 3.000016\nEpoch: 1, [2080/28539], Loss: 2.889499\nEpoch: 1, [2240/28539], Loss: 2.921304\nEpoch: 1, [2400/28539], Loss: 2.914713\nEpoch: 1, [2560/28539], Loss: 2.902354\nEpoch: 1, [2720/28539], Loss: 2.897294\nEpoch: 1, [2880/28539], Loss: 2.906665\nEpoch: 1, [3040/28539], Loss: 2.913656\nEpoch: 1, [3200/28539], Loss: 2.869197\nEpoch: 1, [3360/28539], Loss: 2.862186\nEpoch: 1, [3520/28539], Loss: 2.870985\nEpoch: 1, [3680/28539], Loss: 2.848508\nEpoch: 1, [3840/28539], Loss: 2.857217\nEpoch: 1, [4000/28539], Loss: 2.866502\nEpoch: 1, [4160/28539], Loss: 2.909679\nEpoch: 1, [4320/28539], Loss: 2.913541\nEpoch: 1, [4480/28539], Loss: 2.889457\nEpoch: 1, [4640/28539], Loss: 2.836863\nEpoch: 1, [4800/28539], Loss: 2.880829\nEpoch: 1, [4960/28539], Loss: 2.895662\nEpoch: 1, [5120/28539], Loss: 2.911409\nEpoch: 1, [5280/28539], Loss: 2.871233\nEpoch: 1, [5440/28539], Loss: 2.857660\nEpoch: 1, [5600/28539], Loss: 2.863352\nEpoch: 1, [5760/28539], Loss: 2.848914\nEpoch: 1, [5920/28539], Loss: 2.986295\nEpoch: 1, [6080/28539], Loss: 2.854491\nEpoch: 1, [6240/28539], Loss: 2.887707\nEpoch: 1, [6400/28539], Loss: 2.843832\nEpoch: 1, [6560/28539], Loss: 2.904209\nEpoch: 1, [6720/28539], Loss: 2.856209\nEpoch: 1, [6880/28539], Loss: 2.847819\nEpoch: 1, [7040/28539], Loss: 2.919935\nEpoch: 1, [7200/28539], Loss: 2.881365\nEpoch: 1, [7360/28539], Loss: 2.819353\nEpoch: 1, [7520/28539], Loss: 2.901555\nEpoch: 1, [7680/28539], Loss: 2.886220\nEpoch: 1, [7840/28539], Loss: 2.810987\nEpoch: 1, [8000/28539], Loss: 2.792996\nEpoch: 1, [8160/28539], Loss: 2.830412\nEpoch: 1, [8320/28539], Loss: 2.805928\nEpoch: 1, [8480/28539], Loss: 2.839649\nEpoch: 1, [8640/28539], Loss: 2.864450\nEpoch: 1, [8800/28539], Loss: 2.820161\nEpoch: 1, [8960/28539], Loss: 2.848589\nEpoch: 1, [9120/28539], Loss: 2.835281\nEpoch: 1, [9280/28539], Loss: 2.861884\nEpoch: 1, [9440/28539], Loss: 2.879961\nEpoch: 1, [9600/28539], Loss: 2.864089\nEpoch: 1, [9760/28539], Loss: 2.874547\nEpoch: 1, [9920/28539], Loss: 2.831910\nEpoch: 1, [10080/28539], Loss: 2.909320\nEpoch: 1, [10240/28539], Loss: 2.793735\nEpoch: 1, [10400/28539], Loss: 2.909442\nEpoch: 1, [10560/28539], Loss: 2.834599\nEpoch: 1, [10720/28539], Loss: 2.864381\nEpoch: 1, [10880/28539], Loss: 2.813603\nEpoch: 1, [11040/28539], Loss: 2.857196\nEpoch: 1, [11200/28539], Loss: 2.916079\nEpoch: 1, [11360/28539], Loss: 2.822834\nEpoch: 1, [11520/28539], Loss: 2.865084\nEpoch: 1, [11680/28539], Loss: 2.804953\nEpoch: 1, [11840/28539], Loss: 2.842419\nEpoch: 1, [12000/28539], Loss: 2.858448\nEpoch: 1, [12160/28539], Loss: 2.887420\nEpoch: 1, [12320/28539], Loss: 2.862429\nEpoch: 1, [12480/28539], Loss: 2.879329\nEpoch: 1, [12640/28539], Loss: 2.851887\nEpoch: 1, [12800/28539], Loss: 2.833994\nEpoch: 1, [12960/28539], Loss: 2.873985\nEpoch: 1, [13120/28539], Loss: 2.853928\nEpoch: 1, [13280/28539], Loss: 2.923631\nEpoch: 1, [13440/28539], Loss: 2.867028\nEpoch: 1, [13600/28539], Loss: 2.859457\nEpoch: 1, [13760/28539], Loss: 2.864770\nEpoch: 1, [13920/28539], Loss: 2.968845\nEpoch: 1, [14080/28539], Loss: 2.857745\nEpoch: 1, [14240/28539], Loss: 2.800442\nEpoch: 1, [14400/28539], Loss: 2.848142\nEpoch: 1, [14560/28539], Loss: 2.802380\nEpoch: 1, [14720/28539], Loss: 2.912076\nEpoch: 1, [14880/28539], Loss: 2.850339\nEpoch: 1, [15040/28539], Loss: 2.839202\nEpoch: 1, [15200/28539], Loss: 2.818882\nEpoch: 1, [15360/28539], Loss: 2.858849\nEpoch: 1, [15520/28539], Loss: 2.797590\nEpoch: 1, [15680/28539], Loss: 2.825204\nEpoch: 1, [15840/28539], Loss: 2.826761\nEpoch: 1, [16000/28539], Loss: 2.788623\nEpoch: 1, [16160/28539], Loss: 2.822266\nEpoch: 1, [16320/28539], Loss: 2.868129\nEpoch: 1, [16480/28539], Loss: 2.778893\nEpoch: 1, [16640/28539], Loss: 2.791434\nEpoch: 1, [16800/28539], Loss: 2.831182\nEpoch: 1, [16960/28539], Loss: 2.823523\nEpoch: 1, [17120/28539], Loss: 2.785176\nEpoch: 1, [17280/28539], Loss: 2.881616\nEpoch: 1, [17440/28539], Loss: 2.853776\nEpoch: 1, [17600/28539], Loss: 2.774204\nEpoch: 1, [17760/28539], Loss: 2.787130\nEpoch: 1, [17920/28539], Loss: 2.856998\nEpoch: 1, [18080/28539], Loss: 2.804573\nEpoch: 1, [18240/28539], Loss: 2.761014\nEpoch: 1, [18400/28539], Loss: 2.803659\nEpoch: 1, [18560/28539], Loss: 2.777053\nEpoch: 1, [18720/28539], Loss: 2.718231\nEpoch: 1, [18880/28539], Loss: 2.758467\nEpoch: 1, [19040/28539], Loss: 2.788310\nEpoch: 1, [19200/28539], Loss: 2.811730\nEpoch: 1, [19360/28539], Loss: 2.661617\nEpoch: 1, [19520/28539], Loss: 2.635495\nEpoch: 1, [19680/28539], Loss: 2.664057\nEpoch: 1, [19840/28539], Loss: 2.635445\nEpoch: 1, [20000/28539], Loss: 2.603895\nEpoch: 1, [20160/28539], Loss: 2.579803\nEpoch: 1, [20320/28539], Loss: 2.618420\nEpoch: 1, [20480/28539], Loss: 2.519275\nEpoch: 1, [20640/28539], Loss: 2.539785\nEpoch: 1, [20800/28539], Loss: 2.516602\nEpoch: 1, [20960/28539], Loss: 2.442241\nEpoch: 1, [21120/28539], Loss: 2.413102\nEpoch: 1, [21280/28539], Loss: 2.407520\nEpoch: 1, [21440/28539], Loss: 2.466344\nEpoch: 1, [21600/28539], Loss: 2.477568\nEpoch: 1, [21760/28539], Loss: 2.407083\nEpoch: 1, [21920/28539], Loss: 2.311905\nEpoch: 1, [22080/28539], Loss: 2.282061\nEpoch: 1, [22240/28539], Loss: 2.362991\nEpoch: 1, [22400/28539], Loss: 2.273304\nEpoch: 1, [22560/28539], Loss: 2.271649\nEpoch: 1, [22720/28539], Loss: 2.369935\nEpoch: 1, [22880/28539], Loss: 2.379936\nEpoch: 1, [23040/28539], Loss: 2.257878\nEpoch: 1, [23200/28539], Loss: 2.315193\nEpoch: 1, [23360/28539], Loss: 2.276034\nEpoch: 1, [23520/28539], Loss: 2.230899\nEpoch: 1, [23680/28539], Loss: 2.272393\nEpoch: 1, [23840/28539], Loss: 2.169368\nEpoch: 1, [24000/28539], Loss: 2.162493\nEpoch: 1, [24160/28539], Loss: 2.220423\nEpoch: 1, [24320/28539], Loss: 2.311982\nEpoch: 1, [24480/28539], Loss: 2.177480\nEpoch: 1, [24640/28539], Loss: 2.064229\nEpoch: 1, [24800/28539], Loss: 2.066363\nEpoch: 1, [24960/28539], Loss: 2.084049\nEpoch: 1, [25120/28539], Loss: 2.144766\nEpoch: 1, [25280/28539], Loss: 2.194982\nEpoch: 1, [25440/28539], Loss: 2.091974\nEpoch: 1, [25600/28539], Loss: 1.922488\nEpoch: 1, [25760/28539], Loss: 1.895168\nEpoch: 1, [25920/28539], Loss: 2.093598\nEpoch: 1, [26080/28539], Loss: 1.958380\nEpoch: 1, [26240/28539], Loss: 2.168309\nEpoch: 1, [26400/28539], Loss: 1.855870\nEpoch: 1, [26560/28539], Loss: 2.014034\nEpoch: 1, [26720/28539], Loss: 1.922241\nEpoch: 1, [26880/28539], Loss: 2.020196\nEpoch: 1, [27040/28539], Loss: 1.900557\nEpoch: 1, [27200/28539], Loss: 2.068412\nEpoch: 1, [27360/28539], Loss: 1.659808\nEpoch: 1, [27520/28539], Loss: 1.841997\nEpoch: 1, [27680/28539], Loss: 1.904196\nEpoch: 1, [27840/28539], Loss: 1.705559\nEpoch: 1, [28000/28539], Loss: 1.864474\nEpoch: 1, [28160/28539], Loss: 1.953649\nEpoch: 1, [28320/28539], Loss: 1.802676\nEpoch: 1, [28480/28539], Loss: 1.847697\nEpoch 1 training time: 27.01 minutes\nTesting on dev-clean (epoch=1)\nLoss: 2.058515\nWER: 1.0779\nCER: 0.5827\nTraininig... (e=2)\nEpoch: 2, [0/28539], Loss: 2.011709\nEpoch: 2, [160/28539], Loss: 2.021942\nEpoch: 2, [320/28539], Loss: 1.860675\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot(range(1, epochs + 1), train_loss, label='Training Loss')\nplt.plot(range(1, epochs + 1), dev_loss, label='Dev Loss', linestyle='--')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.title('Loss curves for Training and Validation sets')\nplt.legend()\nplt.grid(True)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T03:46:34.555626Z","iopub.status.idle":"2025-04-16T03:46:34.555853Z","shell.execute_reply.started":"2025-04-16T03:46:34.555747Z","shell.execute_reply":"2025-04-16T03:46:34.555757Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#WER curve\nplt.plot(range(1, epochs + 1), dev_wer, label='WER')\nplt.xlabel('Epochs')\nplt.ylabel('WER')\nplt.title('WER curve for Validation set')\nplt.legend()\nplt.grid(True)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T03:46:34.557015Z","iopub.status.idle":"2025-04-16T03:46:34.557287Z","shell.execute_reply.started":"2025-04-16T03:46:34.557162Z","shell.execute_reply":"2025-04-16T03:46:34.557175Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#CER curve\nplt.plot(range(1, epochs + 1), dev_cer, label='CER')\nplt.xlabel('Epochs')\nplt.ylabel('CER')\nplt.title('CER curve for Validation set')\nplt.legend()\nplt.grid(True)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T03:46:34.558735Z","iopub.status.idle":"2025-04-16T03:46:34.559064Z","shell.execute_reply.started":"2025-04-16T03:46:34.558902Z","shell.execute_reply":"2025-04-16T03:46:34.558918Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}